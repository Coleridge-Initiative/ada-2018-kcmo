{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping - Virginia Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# interacting with websites and web-APIs\n",
    "import requests # easy way to interact with web sites and services\n",
    "import json # read/write JavaScript Object Notation (JSON)\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# from selenium import webdriver\n",
    "# browser = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll start by just copying the URL from our web browser and saving it as a variable:\n",
    "\n",
    "## The real world version of this website can be found here:\n",
    "# url = \"http://www.virginia.gov/localagency/index.html\"\n",
    "\n",
    "## In our development environment, it is here:\n",
    "url = \"http://deepdish.adrf.info/contrib/virginia.html\"\n",
    "\n",
    "response = requests.get(url)\n",
    "print(type(response))\n",
    "\n",
    "## If HTML doesn't load entirely:\n",
    "# browser.get(url)\n",
    "# soup = BeautifulSoup(browser.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the status code (we use str() since this returns an int:\n",
    "print(\"Status code \" + str(response.status_code) )\n",
    "## Returns a status of 200 - that's good.\n",
    "\n",
    "# Header - Content Type\n",
    "print(\"Content type \" + response.headers['content-type'])\n",
    "## We were expecting HTML, so that's good too.\n",
    "\n",
    "# Check the encoding:\n",
    "print(\"Encoding is \" + response.encoding)\n",
    "# UTF-8 is a common encoding that we can easily work with. All good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also print out all the text from the response:\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text)\n",
    "print(type(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Right off the bat, this gives us new methods, like prettify, that make our HTML a lot easier to work with.\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also askour BeautifulSoup object for specific tags, like the title:\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that included the tag itself, but we could just get the text with:\n",
    "soup.title.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or alternatively, just the tag name:\n",
    "soup.title.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works well for <title> since there should only be one for any webpage.\n",
    "# For more common tags, we can use the \"find\" method to grab the first tag of a certain type (and its contents):\n",
    "soup.find(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, yo can find all the tags of a certain type with \"find_all\":\n",
    "soup.find_all(\"button\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get more specific, you can find HTML tags by both their type and attributes:\n",
    "soup.find(\"button\", {\"class\": \"btn_eastern\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find(\"tbody\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instead of printing that out, let's save it as a variable called rows:\n",
    "rows = table.find_all(\"tr\")\n",
    "type(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we can look within each row (below, just the first row) for table elements <td>:\n",
    "rows[0].find_all(\"td\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, we can use the 'findChildren' method.\n",
    "print(rows[0].findChildren('td'))\n",
    "print(rows[1].findChildren('td'))\n",
    "print(rows[2].findChildren('td'))\n",
    "print(rows[3].findChildren('td'))\n",
    "print(rows[4].findChildren('td'))\n",
    "# Note that 'child' is a relative term, refering to a tag within a tag. \n",
    "# The container tag is called the 'parent' tag, likewise relative to the child tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can see that come of these rows have a span element, and some do not:\n",
    "print(rows[0].findChildren(\"span\"))\n",
    "print(rows[1].findChildren(\"span\"))\n",
    "print(rows[2].findChildren(\"span\"))\n",
    "print(rows[3].findChildren(\"span\"))\n",
    "print(rows[4].findChildren(\"span\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directors = [] # create an empty list to store the director names\n",
    "\n",
    "for i in range(0, len(rows) -1): # Perform a loop over the number of rows in the table\n",
    "    row = rows[i] # Subset list to just one row\n",
    "    \n",
    "    director = row.find_all(\"td\")[4].text # grab text within the fifth <td> tag\n",
    "    \n",
    "    directors.append(director) # Add this name to our list\n",
    "    \n",
    "# And now we have a list of the directors of Virginia Social Services agencies:\n",
    "print(directors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agencies = []\n",
    "addresses = []\n",
    "phone_numbers = []\n",
    "\n",
    "for i in range(0, len(rows)-1):\n",
    "    row = rows[i]\n",
    "    \n",
    "    address = row.find_all(\"td\")[1].text\n",
    "    phone_number = row.find_all(\"td\")[4].text\n",
    "    \n",
    "    if row.find(\"span\", {\"class\" : \"ng-scope\"}):\n",
    "        agency = row.find(\"span\", {\"class\" : \"ng-scope\"}).text\n",
    "    elif row.find(\"a\", {\"class\" : \"ng-scope\"}):\n",
    "        agency = row.find(\"a\", {\"class\" : \"ng-scope\"}).text\n",
    "    else:\n",
    "        agency = None\n",
    "        \n",
    "    agencies.append(agency)\n",
    "    addresses.append(address)\n",
    "    phone_numbers.append(phone_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save our scraped data to a new pandas dataframe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a python dictionary (list of key-value pairs)\n",
    "d = {\"agency_name\" : pd.Series(agencies),\n",
    "    \"address\" : pd.Series(addresses),\n",
    "    \"phone_number\" : pd.Series(phone_numbers),\n",
    "    \"director_name\" : pd.Series(directors)}\n",
    "\n",
    "# Easy to convert to recognizable pandas dataframe (tabular data):\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "print(type(d))\n",
    "print(type(df))\n",
    "print(df.shape)\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save our scraped data as a csv:\n",
    "df.to_csv(\"va-social-services.csv\", encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
