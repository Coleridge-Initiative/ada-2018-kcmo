{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing your Datasets\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "    - [Learning Objectives](#Learning-Objectives)\n",
    "    - [Methods](#Methods)\n",
    "- [Python Setup](#Python-Setup)\n",
    "- [Load the Data](#Load-the-Data)\n",
    "    - [Establish a Connection to the Database](#Establish-a-Connection-to-the-Database)\n",
    "    - [Pull Data from the Database](#Pull-Data-from-the-Database)\n",
    "    - [Rename the Variables](#Rename-the-Variables)\n",
    "- [Analysis](#Analysis)\n",
    "- [Getting to know the IDHS database](#Getting-to-know-the-IDHS-database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In an ideal world, we will have all of the data we want with all of the desirable properties (no missing values, no errors, standard formats, and so on). \n",
    "However, that is hardly ever true - and we have to work with using our datasets to answer questions of interest as intelligently as possible. \n",
    "\n",
    "In this notebook, we will discover the datasets we have on the ADRF, and we will use our datasets to answer some questions of interest. \n",
    "\n",
    "### Learning Objectives\n",
    "This notebook will give you the opportunity to spend some hands-on time with the data. \n",
    "\n",
    "You will have an opportunity to explore the different datasets in the ADRF, and this notebook will take you around the different ways you can analyze your data. \n",
    "This involves looking at basic metrics in the larger dataset, taking a random sample, creating derived variables, making sense of the missing values & so on. \n",
    "\n",
    "We will be mostly using SQL (via psycopg2), hence giving you the opportunity to interact with the database directly. The same queries can also be handled by Pandas in Python (by converting your datasets into dataframes). \n",
    "\n",
    "After going through this notebook, you will have a good understanding around: \n",
    "\n",
    "- How to create new tables of interest from the larger tables in database\n",
    "- How to decide on the variables of interest\n",
    "- How to quickly look through aggregate metrics before proceeding with analysis\n",
    "- Possible pitfalls\n",
    "- How to handle missing values\n",
    "- How to join newly created tables\n",
    "- How to think about caveats in your final results\n",
    "\n",
    "### Methods\n",
    "We will be using the `psycopg2` Python package to access tables in our class database  server - PostgreSQL. \n",
    "\n",
    "To read the results of our queries, we will be using the `pandas` Python package, which has the ability to read tabular data from SQL queries into a pandas DataFrame object. Within `pandas`, we will use various commands:\n",
    "\n",
    "- Subsetting data\n",
    "- `groupby`\n",
    "- `merge`\n",
    "\n",
    "Within SQL, we will use various queries:\n",
    "\n",
    "- `CREATE TABLE`\n",
    "- `SELECT ROWS`\n",
    "- Summing over groups\n",
    "- Counting distinct values of desired variables\n",
    "- Ordering data by chosen variables\n",
    "- Selecting a random sub-sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Setup\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In Python, we `import` packages. The `import` command allows us to use libraries created by others in our own work by \"importing\" them. You can think of importing a library as opening up a toolbox and pulling out a specific tool. \n",
    "- NumPy is short for numerical python. NumPy is a lynchpin in Python's scientific computing stack. Its strengths include a powerful *N*-dimensional array object, and a large suite of functions for doing numerical computing. \n",
    "- Pandas is a library in Python for data analysis that uses the DataFrame object from R which is similiar to a spreedsheet but allows you to do your analysis programaticaly rather than the point-and-click of Excel. It is a lynchpin of the PyData stack.  \n",
    "- Psycopg2 is a python library for interfacing with a PostGreSQL database. \n",
    "- Matplotlib is the standard plotting library in python. \n",
    "`%matplotlib inline` is a so-called \"magic\" function of Jupyter that enables plots to be displayed inline with the code and text of a notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# general use imports\n",
    "import datetime\n",
    "import glob\n",
    "import inspect\n",
    "import numpy\n",
    "import os\n",
    "import six\n",
    "import warnings\n",
    "\n",
    "# pandas-related imports\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "\n",
    "# CSV file reading-related imports\n",
    "import csv\n",
    "\n",
    "# database interaction imports\n",
    "import psycopg2\n",
    "import psycopg2.extras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__When in doubt, use shift + tab to read the documentation of a method.__\n",
    "\n",
    "__The `help()` function provides information on what you can do with a function.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Instead of using pgAdmin or the command line sql too directly, we can also carry out sql queries using python. But more power of python and pandas comes from that they can greatly facilitate descpritive statistics of the data, which is rather complicated to do, if not possible, in sql per se. Moreover, python and pandas plus matplotlib package can create data visualizations that greatly helps data analysis. We will see some of these advantages in the following content.\n",
    "\n",
    "Pandas provides many ways to load data. It allows the user to read the data from a local csv or excel file, or pull the data from a relational database. Since we are working with the relational database appliedda in this course, we will demonstrate how to use pandas to read data from a relational database. For examples to read data from a csv file, refert to the pandas documentation [Getting Data In/Out](pandas.pydata.org/pandas-docs/stable/10min.html#getting-data-in-out).\n",
    "\n",
    "The function to create a sql query and put the data into a pandas dataframe (more to come) is `pd.read_sql()`. Just like doing a sql query from pgAdmin, this function will ask for some information about the database, and what query you woul like to run. Let's walk through the example below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish a Connection to the Database with `psycopg2`\n",
    "In the most simple case, only 2 parameters are required by the `pd.read_sql()` function to pull data. The first parameter is the connection to the database. To create a connection we need to use the psycopg2 package and tell it which database and which host we want to connect to, just like in pgAdmin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter 1: Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to create a connection to the database, we need to pass the name of the database and host of the database\n",
    "# db_name = \"appliedda\"\n",
    "# db_host = \"10.10.2.10\"\n",
    "# conn = psycopg2.connect(database=db_name, host=db_host) #database connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter 2: Query\n",
    "This part is similar to writing a sql query in pgAdmin. Depending on what data we are interested in, we can use different queries to pull different data. In this example, we will pull all the content of wage_person data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# query = '''\n",
    "# SELECT *\n",
    "# FROM idhs.hh_indcase_spells h\n",
    "# WHERE h.start_date >= '2015-01-01' AND h.end_date <= '2015-03-31'\n",
    "# '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "- the three quotation marks surrounding the query body is called multi-line string. It is quite handy for writing sql queries because the new line character will be considered part of the string, instead of breaking the string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull Data from the Database\n",
    "Now that we know what the arguments are for the query, we can pass them to the `pd.read_sql()` function, and obtain the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here we pass the query and the connection to the pd.read_sql() function and assign the variable `business_licenses` \n",
    "# to the dataframe returned by the function\n",
    "# business_licenses = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename the Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# business_licenses.columns = ['business_activity', 'address', 'legal_name', 'dba_name', 'filing_period']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"background-color: #FFFF00\"> TEMP </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "business_licenses = pd.read_csv('../../data/KCMO/BusinessLicense2013_2018NYU_01222018.csv')\n",
    "# od_main_JT01 = pd.read_csv('../../data/LODES/mo_od_main_JT01.csv')\n",
    "xwalk = pd.read_csv('../../data/LODES/raw/mo_xwalk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_licenses = business_licenses[business_licenses['fdtmfilingPeriod']=='12/31/17'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wac = wac[wac['cbsaname']==\"Kansas City, MO-KS\"].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_licenses.columns = ['business_activity', 'address', 'legal_name', 'dba_name', 'filing_period']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "__What is the current distribution of jobs by industrial sector across Kansas City, MO? What is the trend over the last 10 years?__\n",
    "\n",
    "__Other interesting questions we can answer using same/similar datasets__\n",
    "- How many blocks have industry jobs in Kansas City, MO?\n",
    "- To what extent to the different counties that make up Kansas City, MO, differ in job?\n",
    "- Distribution of these jobs by gender, race, age, income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: What is in the database?\n",
    "\n",
    "In this preliminary step, you will have a chance to discover the datasets in the ADRF that we presented this morning. These include the Census LODES data, KCMO water services data, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ LODES Data: Workplace Area Characteristics File__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# query = '''\n",
    "# SELECT *\n",
    "# FROM mo_wac\n",
    "# LIMIT 100\n",
    "# '''\n",
    "\n",
    "# wac = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TEMP\n",
    "wac = pd.read_csv('../../data/LODES/mo_wac_S000_JT01.csv')\n",
    "wac['w_geocode'] = wac['w_geocode'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_geocode</th>\n",
       "      <th>C000</th>\n",
       "      <th>CA01</th>\n",
       "      <th>CA02</th>\n",
       "      <th>CA03</th>\n",
       "      <th>CE01</th>\n",
       "      <th>CE02</th>\n",
       "      <th>CE03</th>\n",
       "      <th>CNS01</th>\n",
       "      <th>CNS02</th>\n",
       "      <th>...</th>\n",
       "      <th>CFA03</th>\n",
       "      <th>CFA04</th>\n",
       "      <th>CFA05</th>\n",
       "      <th>CFS01</th>\n",
       "      <th>CFS02</th>\n",
       "      <th>CFS03</th>\n",
       "      <th>CFS04</th>\n",
       "      <th>CFS05</th>\n",
       "      <th>createdate</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>290019501001008</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20160219</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>290019501001022</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20160219</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>290019501001025</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20160219</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>290019501001055</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20160219</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>290019501001128</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20160219</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         w_geocode  C000  CA01  CA02  CA03  CE01  CE02  CE03  CNS01  CNS02  \\\n",
       "0  290019501001008     3     0     3     0     2     1     0      0      0   \n",
       "1  290019501001022     2     0     2     0     0     2     0      0      0   \n",
       "2  290019501001025     2     0     2     0     0     0     2      2      0   \n",
       "3  290019501001055     1     1     0     0     0     1     0      0      0   \n",
       "4  290019501001128     1     0     1     0     0     1     0      0      0   \n",
       "\n",
       "   ...   CFA03  CFA04  CFA05  CFS01  CFS02  CFS03  CFS04  CFS05  createdate  \\\n",
       "0  ...       0      0      0      0      0      0      0      0    20160219   \n",
       "1  ...       0      0      0      0      0      0      0      0    20160219   \n",
       "2  ...       0      0      0      0      0      0      0      0    20160219   \n",
       "3  ...       0      0      0      0      0      0      0      0    20160219   \n",
       "4  ...       0      0      0      0      0      0      0      0    20160219   \n",
       "\n",
       "   year  \n",
       "0  2014  \n",
       "1  2014  \n",
       "2  2014  \n",
       "3  2014  \n",
       "4  2014  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wac.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['w_geocode', 'C000', 'CA01', 'CA02', 'CA03', 'CE01', 'CE02', 'CE03',\n",
       "       'CNS01', 'CNS02', 'CNS03', 'CNS04', 'CNS05', 'CNS06', 'CNS07', 'CNS08',\n",
       "       'CNS09', 'CNS10', 'CNS11', 'CNS12', 'CNS13', 'CNS14', 'CNS15', 'CNS16',\n",
       "       'CNS17', 'CNS18', 'CNS19', 'CNS20', 'CR01', 'CR02', 'CR03', 'CR04',\n",
       "       'CR05', 'CR07', 'CT01', 'CT02', 'CD01', 'CD02', 'CD03', 'CD04', 'CS01',\n",
       "       'CS02', 'CFA01', 'CFA02', 'CFA03', 'CFA04', 'CFA05', 'CFS01', 'CFS02',\n",
       "       'CFS03', 'CFS04', 'CFS05', 'createdate', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wac.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take some time to look at the documentation and understant what the different column names refer to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ LODES Data: Crosswalk File __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# query = '''\n",
    "# SELECT *\n",
    "# FROM mo_xwalk\n",
    "# '''\n",
    "\n",
    "# xwalk = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nj995/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# TEMP\n",
    "xwalk = pd.read_csv('../../data/LODES/mo_xwalk.csv')\n",
    "xwalk = xwalk.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tabblk2010</th>\n",
       "      <th>st</th>\n",
       "      <th>stusps</th>\n",
       "      <th>stname</th>\n",
       "      <th>cty</th>\n",
       "      <th>ctyname</th>\n",
       "      <th>trct</th>\n",
       "      <th>trctname</th>\n",
       "      <th>bgrp</th>\n",
       "      <th>bgrpname</th>\n",
       "      <th>...</th>\n",
       "      <th>stanrcname</th>\n",
       "      <th>necta</th>\n",
       "      <th>nectaname</th>\n",
       "      <th>mil</th>\n",
       "      <th>milname</th>\n",
       "      <th>stwib</th>\n",
       "      <th>stwibname</th>\n",
       "      <th>blklatdd</th>\n",
       "      <th>blklondd</th>\n",
       "      <th>createdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>343565</td>\n",
       "      <td>343565</td>\n",
       "      <td>343565</td>\n",
       "      <td>343565</td>\n",
       "      <td>343565</td>\n",
       "      <td>343565</td>\n",
       "      <td>343565</td>\n",
       "      <td>343565</td>\n",
       "      <td>343565</td>\n",
       "      <td>343565</td>\n",
       "      <td>...</td>\n",
       "      <td>343565</td>\n",
       "      <td>343565</td>\n",
       "      <td>343565</td>\n",
       "      <td>343565</td>\n",
       "      <td>343565</td>\n",
       "      <td>343565</td>\n",
       "      <td>343565</td>\n",
       "      <td>343565</td>\n",
       "      <td>343565</td>\n",
       "      <td>343565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>343565</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>1393</td>\n",
       "      <td>1393</td>\n",
       "      <td>4506</td>\n",
       "      <td>4506</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>341645</td>\n",
       "      <td>342168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>291059602985179</td>\n",
       "      <td>29</td>\n",
       "      <td>MO</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>29189</td>\n",
       "      <td>St. Louis County, MO</td>\n",
       "      <td>29007950200</td>\n",
       "      <td>9502 (Audrain, MO)</td>\n",
       "      <td>290414701002</td>\n",
       "      <td>2 (Tract 4701, Chariton, MO)</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>99999</td>\n",
       "      <td>nan</td>\n",
       "      <td>9999999999999999999999</td>\n",
       "      <td>nan</td>\n",
       "      <td>29290016</td>\n",
       "      <td>5/9 Central Region WIB</td>\n",
       "      <td>37.2056999</td>\n",
       "      <td>-94.5382808</td>\n",
       "      <td>20170919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>343565</td>\n",
       "      <td>343565</td>\n",
       "      <td>343565</td>\n",
       "      <td>18737</td>\n",
       "      <td>18737</td>\n",
       "      <td>1401</td>\n",
       "      <td>1401</td>\n",
       "      <td>755</td>\n",
       "      <td>755</td>\n",
       "      <td>...</td>\n",
       "      <td>343565</td>\n",
       "      <td>343565</td>\n",
       "      <td>343565</td>\n",
       "      <td>342094</td>\n",
       "      <td>342094</td>\n",
       "      <td>49276</td>\n",
       "      <td>49276</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>343565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             tabblk2010      st  stusps    stname     cty  \\\n",
       "count            343565  343565  343565    343565  343565   \n",
       "unique           343565       1       1         1     115   \n",
       "top     291059602985179      29      MO  Missouri   29189   \n",
       "freq                  1  343565  343565    343565   18737   \n",
       "\n",
       "                     ctyname         trct            trctname          bgrp  \\\n",
       "count                 343565       343565              343565        343565   \n",
       "unique                   115         1393                1393          4506   \n",
       "top     St. Louis County, MO  29007950200  9502 (Audrain, MO)  290414701002   \n",
       "freq                   18737         1401                1401           755   \n",
       "\n",
       "                            bgrpname    ...     stanrcname   necta nectaname  \\\n",
       "count                         343565    ...         343565  343565    343565   \n",
       "unique                          4506    ...              1       1         1   \n",
       "top     2 (Tract 4701, Chariton, MO)    ...            nan   99999       nan   \n",
       "freq                             755    ...         343565  343565    343565   \n",
       "\n",
       "                           mil milname     stwib               stwibname  \\\n",
       "count                   343565  343565    343565                  343565   \n",
       "unique                      10      10        14                      14   \n",
       "top     9999999999999999999999     nan  29290016  5/9 Central Region WIB   \n",
       "freq                    342094  342094     49276                   49276   \n",
       "\n",
       "          blklatdd     blklondd createdate  \n",
       "count       343565       343565     343565  \n",
       "unique      341645       342168          1  \n",
       "top     37.2056999  -94.5382808   20170919  \n",
       "freq             4            3     343565  \n",
       "\n",
       "[4 rows x 43 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xwalk.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, take some time to look at the documentation and understand all the levels of geography in the crosswalk file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Water Services: Consumption Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# query = '''\n",
    "# SELECT *\n",
    "# FROM water\n",
    "# LIMIT 100\n",
    "# '''\n",
    "\n",
    "# water = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Summary Statistics in Different Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, let's start looking at aggregate statistics on the data. We are interested in the distribution of jobs by industrial classification, so let's take a look at the overall distribution in 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# query = '''\n",
    "# SELECT\n",
    "#     year\n",
    "#     , sum(CNS01) as CNS01\n",
    "#     , sum(CNS02) as CNS02\n",
    "#     , sum(CNS03) as CNS03\n",
    "#     , sum(CNS04) as CNS04\n",
    "#     , sum(CNS05) as CNS05\n",
    "#     , sum(CNS06) as CNS06\n",
    "#     , sum(CNS07) as CNS07\n",
    "#     , sum(CNS08) as CNS08\n",
    "#     , sum(CNS09) as CNS09\n",
    "#     , sum(CNS10) as CNS10\n",
    "#     , sum(CNS11) as CNS11\n",
    "#     , sum(CNS12) as CNS12\n",
    "#     , sum(CNS13) as CNS13\n",
    "#     , sum(CNS14) as CNS14\n",
    "#     , sum(CNS15) as CNS15\n",
    "#     , sum(CNS16) as CNS16\n",
    "#     , sum(CNS17) as CNS17\n",
    "#     , sum(CNS18) as CNS18\n",
    "#     , sum(CNS19) as CNS19\n",
    "#     , sum(CNS20) as CNS20\n",
    "# FROM mo_wac\n",
    "# GROUP BY year\n",
    "# LIMIT 100\n",
    "# '''\n",
    "# wac_year_stats = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TEMP:\n",
    "filter_col = [col for col in wac if col.startswith('CN')]\n",
    "wac_year_stats = wac_year_stats.groupby('year')[filter_col].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNS01</th>\n",
       "      <th>CNS02</th>\n",
       "      <th>CNS03</th>\n",
       "      <th>CNS04</th>\n",
       "      <th>CNS05</th>\n",
       "      <th>CNS06</th>\n",
       "      <th>CNS07</th>\n",
       "      <th>CNS08</th>\n",
       "      <th>CNS09</th>\n",
       "      <th>CNS10</th>\n",
       "      <th>CNS11</th>\n",
       "      <th>CNS12</th>\n",
       "      <th>CNS13</th>\n",
       "      <th>CNS14</th>\n",
       "      <th>CNS15</th>\n",
       "      <th>CNS16</th>\n",
       "      <th>CNS17</th>\n",
       "      <th>CNS18</th>\n",
       "      <th>CNS19</th>\n",
       "      <th>CNS20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>10397.0</td>\n",
       "      <td>3827.0</td>\n",
       "      <td>13979.0</td>\n",
       "      <td>136760.0</td>\n",
       "      <td>311954.0</td>\n",
       "      <td>112754.0</td>\n",
       "      <td>279573.0</td>\n",
       "      <td>88867.0</td>\n",
       "      <td>59828.0</td>\n",
       "      <td>100939.0</td>\n",
       "      <td>37023.0</td>\n",
       "      <td>109010.0</td>\n",
       "      <td>48706.0</td>\n",
       "      <td>112376.0</td>\n",
       "      <td>220609.0</td>\n",
       "      <td>294074.0</td>\n",
       "      <td>37138.0</td>\n",
       "      <td>187232.0</td>\n",
       "      <td>72553.0</td>\n",
       "      <td>110106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>10034.0</td>\n",
       "      <td>3716.0</td>\n",
       "      <td>16832.0</td>\n",
       "      <td>139420.0</td>\n",
       "      <td>293223.0</td>\n",
       "      <td>113426.0</td>\n",
       "      <td>282092.0</td>\n",
       "      <td>92457.0</td>\n",
       "      <td>58018.0</td>\n",
       "      <td>103069.0</td>\n",
       "      <td>36392.0</td>\n",
       "      <td>107358.0</td>\n",
       "      <td>59556.0</td>\n",
       "      <td>118067.0</td>\n",
       "      <td>206306.0</td>\n",
       "      <td>295460.0</td>\n",
       "      <td>45264.0</td>\n",
       "      <td>190848.0</td>\n",
       "      <td>76228.0</td>\n",
       "      <td>93128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>9817.0</td>\n",
       "      <td>4097.0</td>\n",
       "      <td>17762.0</td>\n",
       "      <td>143734.0</td>\n",
       "      <td>290710.0</td>\n",
       "      <td>111971.0</td>\n",
       "      <td>281492.0</td>\n",
       "      <td>88402.0</td>\n",
       "      <td>57023.0</td>\n",
       "      <td>103500.0</td>\n",
       "      <td>36279.0</td>\n",
       "      <td>108889.0</td>\n",
       "      <td>63204.0</td>\n",
       "      <td>121280.0</td>\n",
       "      <td>205007.0</td>\n",
       "      <td>302838.0</td>\n",
       "      <td>45198.0</td>\n",
       "      <td>195623.0</td>\n",
       "      <td>75942.0</td>\n",
       "      <td>87468.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>9900.0</td>\n",
       "      <td>4616.0</td>\n",
       "      <td>17754.0</td>\n",
       "      <td>144243.0</td>\n",
       "      <td>288224.0</td>\n",
       "      <td>115217.0</td>\n",
       "      <td>288305.0</td>\n",
       "      <td>89998.0</td>\n",
       "      <td>57488.0</td>\n",
       "      <td>104219.0</td>\n",
       "      <td>36657.0</td>\n",
       "      <td>111530.0</td>\n",
       "      <td>67252.0</td>\n",
       "      <td>125585.0</td>\n",
       "      <td>207191.0</td>\n",
       "      <td>307181.0</td>\n",
       "      <td>46072.0</td>\n",
       "      <td>200849.0</td>\n",
       "      <td>77264.0</td>\n",
       "      <td>88020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>10856.0</td>\n",
       "      <td>4779.0</td>\n",
       "      <td>18016.0</td>\n",
       "      <td>150242.0</td>\n",
       "      <td>285360.0</td>\n",
       "      <td>115831.0</td>\n",
       "      <td>287137.0</td>\n",
       "      <td>93054.0</td>\n",
       "      <td>55294.0</td>\n",
       "      <td>111344.0</td>\n",
       "      <td>35703.0</td>\n",
       "      <td>116682.0</td>\n",
       "      <td>67378.0</td>\n",
       "      <td>130874.0</td>\n",
       "      <td>209107.0</td>\n",
       "      <td>308742.0</td>\n",
       "      <td>46327.0</td>\n",
       "      <td>203765.0</td>\n",
       "      <td>76123.0</td>\n",
       "      <td>87835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>11089.0</td>\n",
       "      <td>4892.0</td>\n",
       "      <td>18658.0</td>\n",
       "      <td>149831.0</td>\n",
       "      <td>286289.0</td>\n",
       "      <td>118608.0</td>\n",
       "      <td>287227.0</td>\n",
       "      <td>92386.0</td>\n",
       "      <td>55217.0</td>\n",
       "      <td>114034.0</td>\n",
       "      <td>36476.0</td>\n",
       "      <td>120387.0</td>\n",
       "      <td>67940.0</td>\n",
       "      <td>129533.0</td>\n",
       "      <td>219910.0</td>\n",
       "      <td>327249.0</td>\n",
       "      <td>45861.0</td>\n",
       "      <td>206748.0</td>\n",
       "      <td>75979.0</td>\n",
       "      <td>90666.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>10255.0</td>\n",
       "      <td>4817.0</td>\n",
       "      <td>19453.0</td>\n",
       "      <td>150336.0</td>\n",
       "      <td>281021.0</td>\n",
       "      <td>121869.0</td>\n",
       "      <td>281293.0</td>\n",
       "      <td>93378.0</td>\n",
       "      <td>52701.0</td>\n",
       "      <td>111795.0</td>\n",
       "      <td>37023.0</td>\n",
       "      <td>126551.0</td>\n",
       "      <td>65895.0</td>\n",
       "      <td>132946.0</td>\n",
       "      <td>228224.0</td>\n",
       "      <td>339845.0</td>\n",
       "      <td>46058.0</td>\n",
       "      <td>211911.0</td>\n",
       "      <td>78319.0</td>\n",
       "      <td>93324.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>10183.0</td>\n",
       "      <td>4163.0</td>\n",
       "      <td>20002.0</td>\n",
       "      <td>128946.0</td>\n",
       "      <td>246021.0</td>\n",
       "      <td>115904.0</td>\n",
       "      <td>271990.0</td>\n",
       "      <td>87496.0</td>\n",
       "      <td>51565.0</td>\n",
       "      <td>109001.0</td>\n",
       "      <td>35085.0</td>\n",
       "      <td>120245.0</td>\n",
       "      <td>62247.0</td>\n",
       "      <td>119204.0</td>\n",
       "      <td>234191.0</td>\n",
       "      <td>356447.0</td>\n",
       "      <td>44981.0</td>\n",
       "      <td>204969.0</td>\n",
       "      <td>76893.0</td>\n",
       "      <td>95289.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>10367.0</td>\n",
       "      <td>4214.0</td>\n",
       "      <td>19600.0</td>\n",
       "      <td>114038.0</td>\n",
       "      <td>231363.0</td>\n",
       "      <td>116023.0</td>\n",
       "      <td>272633.0</td>\n",
       "      <td>83644.0</td>\n",
       "      <td>49810.0</td>\n",
       "      <td>110198.0</td>\n",
       "      <td>33794.0</td>\n",
       "      <td>119009.0</td>\n",
       "      <td>63438.0</td>\n",
       "      <td>129147.0</td>\n",
       "      <td>225718.0</td>\n",
       "      <td>367974.0</td>\n",
       "      <td>44738.0</td>\n",
       "      <td>207802.0</td>\n",
       "      <td>76995.0</td>\n",
       "      <td>118824.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>10979.0</td>\n",
       "      <td>4126.0</td>\n",
       "      <td>19876.0</td>\n",
       "      <td>113558.0</td>\n",
       "      <td>236305.0</td>\n",
       "      <td>115771.0</td>\n",
       "      <td>277666.0</td>\n",
       "      <td>85641.0</td>\n",
       "      <td>47875.0</td>\n",
       "      <td>108830.0</td>\n",
       "      <td>33436.0</td>\n",
       "      <td>121230.0</td>\n",
       "      <td>65657.0</td>\n",
       "      <td>138280.0</td>\n",
       "      <td>220691.0</td>\n",
       "      <td>377145.0</td>\n",
       "      <td>42667.0</td>\n",
       "      <td>207703.0</td>\n",
       "      <td>81379.0</td>\n",
       "      <td>117910.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>11154.0</td>\n",
       "      <td>4101.0</td>\n",
       "      <td>19343.0</td>\n",
       "      <td>113991.0</td>\n",
       "      <td>232107.0</td>\n",
       "      <td>117953.0</td>\n",
       "      <td>278088.0</td>\n",
       "      <td>86967.0</td>\n",
       "      <td>46800.0</td>\n",
       "      <td>112123.0</td>\n",
       "      <td>33089.0</td>\n",
       "      <td>127092.0</td>\n",
       "      <td>63017.0</td>\n",
       "      <td>134479.0</td>\n",
       "      <td>220297.0</td>\n",
       "      <td>383403.0</td>\n",
       "      <td>46467.0</td>\n",
       "      <td>210723.0</td>\n",
       "      <td>82033.0</td>\n",
       "      <td>113532.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>11488.0</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>19384.0</td>\n",
       "      <td>113095.0</td>\n",
       "      <td>230898.0</td>\n",
       "      <td>120377.0</td>\n",
       "      <td>274702.0</td>\n",
       "      <td>88253.0</td>\n",
       "      <td>47699.0</td>\n",
       "      <td>116559.0</td>\n",
       "      <td>32919.0</td>\n",
       "      <td>134233.0</td>\n",
       "      <td>65432.0</td>\n",
       "      <td>138782.0</td>\n",
       "      <td>221917.0</td>\n",
       "      <td>398709.0</td>\n",
       "      <td>46819.0</td>\n",
       "      <td>213078.0</td>\n",
       "      <td>71272.0</td>\n",
       "      <td>111975.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>11952.0</td>\n",
       "      <td>3859.0</td>\n",
       "      <td>19528.0</td>\n",
       "      <td>121041.0</td>\n",
       "      <td>231934.0</td>\n",
       "      <td>120869.0</td>\n",
       "      <td>278525.0</td>\n",
       "      <td>90252.0</td>\n",
       "      <td>45521.0</td>\n",
       "      <td>113177.0</td>\n",
       "      <td>33757.0</td>\n",
       "      <td>136193.0</td>\n",
       "      <td>70213.0</td>\n",
       "      <td>140249.0</td>\n",
       "      <td>224189.0</td>\n",
       "      <td>404886.0</td>\n",
       "      <td>47499.0</td>\n",
       "      <td>216640.0</td>\n",
       "      <td>70980.0</td>\n",
       "      <td>112535.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>11955.0</td>\n",
       "      <td>3913.0</td>\n",
       "      <td>19159.0</td>\n",
       "      <td>121537.0</td>\n",
       "      <td>235017.0</td>\n",
       "      <td>121758.0</td>\n",
       "      <td>281018.0</td>\n",
       "      <td>92542.0</td>\n",
       "      <td>45734.0</td>\n",
       "      <td>113166.0</td>\n",
       "      <td>34398.0</td>\n",
       "      <td>142310.0</td>\n",
       "      <td>69696.0</td>\n",
       "      <td>145522.0</td>\n",
       "      <td>225545.0</td>\n",
       "      <td>409878.0</td>\n",
       "      <td>45441.0</td>\n",
       "      <td>223366.0</td>\n",
       "      <td>72068.0</td>\n",
       "      <td>113252.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CNS01   CNS02    CNS03     CNS04     CNS05     CNS06     CNS07  \\\n",
       "year                                                                     \n",
       "2002  10397.0  3827.0  13979.0  136760.0  311954.0  112754.0  279573.0   \n",
       "2003  10034.0  3716.0  16832.0  139420.0  293223.0  113426.0  282092.0   \n",
       "2004   9817.0  4097.0  17762.0  143734.0  290710.0  111971.0  281492.0   \n",
       "2005   9900.0  4616.0  17754.0  144243.0  288224.0  115217.0  288305.0   \n",
       "2006  10856.0  4779.0  18016.0  150242.0  285360.0  115831.0  287137.0   \n",
       "2007  11089.0  4892.0  18658.0  149831.0  286289.0  118608.0  287227.0   \n",
       "2008  10255.0  4817.0  19453.0  150336.0  281021.0  121869.0  281293.0   \n",
       "2009  10183.0  4163.0  20002.0  128946.0  246021.0  115904.0  271990.0   \n",
       "2010  10367.0  4214.0  19600.0  114038.0  231363.0  116023.0  272633.0   \n",
       "2011  10979.0  4126.0  19876.0  113558.0  236305.0  115771.0  277666.0   \n",
       "2012  11154.0  4101.0  19343.0  113991.0  232107.0  117953.0  278088.0   \n",
       "2013  11488.0  4094.0  19384.0  113095.0  230898.0  120377.0  274702.0   \n",
       "2014  11952.0  3859.0  19528.0  121041.0  231934.0  120869.0  278525.0   \n",
       "2015  11955.0  3913.0  19159.0  121537.0  235017.0  121758.0  281018.0   \n",
       "\n",
       "        CNS08    CNS09     CNS10    CNS11     CNS12    CNS13     CNS14  \\\n",
       "year                                                                     \n",
       "2002  88867.0  59828.0  100939.0  37023.0  109010.0  48706.0  112376.0   \n",
       "2003  92457.0  58018.0  103069.0  36392.0  107358.0  59556.0  118067.0   \n",
       "2004  88402.0  57023.0  103500.0  36279.0  108889.0  63204.0  121280.0   \n",
       "2005  89998.0  57488.0  104219.0  36657.0  111530.0  67252.0  125585.0   \n",
       "2006  93054.0  55294.0  111344.0  35703.0  116682.0  67378.0  130874.0   \n",
       "2007  92386.0  55217.0  114034.0  36476.0  120387.0  67940.0  129533.0   \n",
       "2008  93378.0  52701.0  111795.0  37023.0  126551.0  65895.0  132946.0   \n",
       "2009  87496.0  51565.0  109001.0  35085.0  120245.0  62247.0  119204.0   \n",
       "2010  83644.0  49810.0  110198.0  33794.0  119009.0  63438.0  129147.0   \n",
       "2011  85641.0  47875.0  108830.0  33436.0  121230.0  65657.0  138280.0   \n",
       "2012  86967.0  46800.0  112123.0  33089.0  127092.0  63017.0  134479.0   \n",
       "2013  88253.0  47699.0  116559.0  32919.0  134233.0  65432.0  138782.0   \n",
       "2014  90252.0  45521.0  113177.0  33757.0  136193.0  70213.0  140249.0   \n",
       "2015  92542.0  45734.0  113166.0  34398.0  142310.0  69696.0  145522.0   \n",
       "\n",
       "         CNS15     CNS16    CNS17     CNS18    CNS19     CNS20  \n",
       "year                                                            \n",
       "2002  220609.0  294074.0  37138.0  187232.0  72553.0  110106.0  \n",
       "2003  206306.0  295460.0  45264.0  190848.0  76228.0   93128.0  \n",
       "2004  205007.0  302838.0  45198.0  195623.0  75942.0   87468.0  \n",
       "2005  207191.0  307181.0  46072.0  200849.0  77264.0   88020.0  \n",
       "2006  209107.0  308742.0  46327.0  203765.0  76123.0   87835.0  \n",
       "2007  219910.0  327249.0  45861.0  206748.0  75979.0   90666.0  \n",
       "2008  228224.0  339845.0  46058.0  211911.0  78319.0   93324.0  \n",
       "2009  234191.0  356447.0  44981.0  204969.0  76893.0   95289.0  \n",
       "2010  225718.0  367974.0  44738.0  207802.0  76995.0  118824.0  \n",
       "2011  220691.0  377145.0  42667.0  207703.0  81379.0  117910.0  \n",
       "2012  220297.0  383403.0  46467.0  210723.0  82033.0  113532.0  \n",
       "2013  221917.0  398709.0  46819.0  213078.0  71272.0  111975.0  \n",
       "2014  224189.0  404886.0  47499.0  216640.0  70980.0  112535.0  \n",
       "2015  225545.0  409878.0  45441.0  223366.0  72068.0  113252.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wac_year_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change there values into the percentage of all jobs that year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wac_year_stats['total_jobs'] = wac_year_stats.sum(axis=1)\n",
    "for var in filter_col:\n",
    "    wac_year_stats[var] = wac_year_stats[var]/wac_year_stats['total_jobs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNS01</th>\n",
       "      <th>CNS02</th>\n",
       "      <th>CNS03</th>\n",
       "      <th>CNS04</th>\n",
       "      <th>CNS05</th>\n",
       "      <th>CNS06</th>\n",
       "      <th>CNS07</th>\n",
       "      <th>CNS08</th>\n",
       "      <th>CNS09</th>\n",
       "      <th>CNS10</th>\n",
       "      <th>...</th>\n",
       "      <th>CNS12</th>\n",
       "      <th>CNS13</th>\n",
       "      <th>CNS14</th>\n",
       "      <th>CNS15</th>\n",
       "      <th>CNS16</th>\n",
       "      <th>CNS17</th>\n",
       "      <th>CNS18</th>\n",
       "      <th>CNS19</th>\n",
       "      <th>CNS20</th>\n",
       "      <th>total_jobs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.002977</td>\n",
       "      <td>0.029126</td>\n",
       "      <td>0.066438</td>\n",
       "      <td>0.024014</td>\n",
       "      <td>0.059542</td>\n",
       "      <td>0.018926</td>\n",
       "      <td>0.012742</td>\n",
       "      <td>0.021497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023216</td>\n",
       "      <td>0.010373</td>\n",
       "      <td>0.023933</td>\n",
       "      <td>0.046984</td>\n",
       "      <td>0.062630</td>\n",
       "      <td>0.007909</td>\n",
       "      <td>0.039876</td>\n",
       "      <td>0.015452</td>\n",
       "      <td>0.023450</td>\n",
       "      <td>4695410.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.003595</td>\n",
       "      <td>0.029779</td>\n",
       "      <td>0.062631</td>\n",
       "      <td>0.024227</td>\n",
       "      <td>0.060253</td>\n",
       "      <td>0.019748</td>\n",
       "      <td>0.012392</td>\n",
       "      <td>0.022015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022931</td>\n",
       "      <td>0.012721</td>\n",
       "      <td>0.025218</td>\n",
       "      <td>0.044066</td>\n",
       "      <td>0.063108</td>\n",
       "      <td>0.009668</td>\n",
       "      <td>0.040764</td>\n",
       "      <td>0.016282</td>\n",
       "      <td>0.019892</td>\n",
       "      <td>4681788.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.003779</td>\n",
       "      <td>0.030579</td>\n",
       "      <td>0.061847</td>\n",
       "      <td>0.023821</td>\n",
       "      <td>0.059886</td>\n",
       "      <td>0.018807</td>\n",
       "      <td>0.012131</td>\n",
       "      <td>0.022019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023166</td>\n",
       "      <td>0.013446</td>\n",
       "      <td>0.025802</td>\n",
       "      <td>0.043614</td>\n",
       "      <td>0.064427</td>\n",
       "      <td>0.009616</td>\n",
       "      <td>0.041618</td>\n",
       "      <td>0.016156</td>\n",
       "      <td>0.018608</td>\n",
       "      <td>4700472.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.003718</td>\n",
       "      <td>0.030207</td>\n",
       "      <td>0.060359</td>\n",
       "      <td>0.024129</td>\n",
       "      <td>0.060376</td>\n",
       "      <td>0.018847</td>\n",
       "      <td>0.012039</td>\n",
       "      <td>0.021825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023356</td>\n",
       "      <td>0.014084</td>\n",
       "      <td>0.026300</td>\n",
       "      <td>0.043390</td>\n",
       "      <td>0.064329</td>\n",
       "      <td>0.009648</td>\n",
       "      <td>0.042061</td>\n",
       "      <td>0.016181</td>\n",
       "      <td>0.018433</td>\n",
       "      <td>4775130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>0.002248</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.003731</td>\n",
       "      <td>0.031113</td>\n",
       "      <td>0.059094</td>\n",
       "      <td>0.023987</td>\n",
       "      <td>0.059462</td>\n",
       "      <td>0.019270</td>\n",
       "      <td>0.011451</td>\n",
       "      <td>0.023058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024163</td>\n",
       "      <td>0.013953</td>\n",
       "      <td>0.027102</td>\n",
       "      <td>0.043303</td>\n",
       "      <td>0.063936</td>\n",
       "      <td>0.009594</td>\n",
       "      <td>0.042197</td>\n",
       "      <td>0.015764</td>\n",
       "      <td>0.018189</td>\n",
       "      <td>4828898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>0.002255</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.003794</td>\n",
       "      <td>0.030466</td>\n",
       "      <td>0.058213</td>\n",
       "      <td>0.024117</td>\n",
       "      <td>0.058404</td>\n",
       "      <td>0.018785</td>\n",
       "      <td>0.011228</td>\n",
       "      <td>0.023187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024479</td>\n",
       "      <td>0.013815</td>\n",
       "      <td>0.026339</td>\n",
       "      <td>0.044716</td>\n",
       "      <td>0.066542</td>\n",
       "      <td>0.009325</td>\n",
       "      <td>0.042039</td>\n",
       "      <td>0.015449</td>\n",
       "      <td>0.018436</td>\n",
       "      <td>4917960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.030224</td>\n",
       "      <td>0.056498</td>\n",
       "      <td>0.024501</td>\n",
       "      <td>0.056552</td>\n",
       "      <td>0.018773</td>\n",
       "      <td>0.010595</td>\n",
       "      <td>0.022476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025442</td>\n",
       "      <td>0.013248</td>\n",
       "      <td>0.026728</td>\n",
       "      <td>0.045883</td>\n",
       "      <td>0.068324</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>0.042603</td>\n",
       "      <td>0.015746</td>\n",
       "      <td>0.018762</td>\n",
       "      <td>4974028.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>0.026922</td>\n",
       "      <td>0.051365</td>\n",
       "      <td>0.024199</td>\n",
       "      <td>0.056787</td>\n",
       "      <td>0.018268</td>\n",
       "      <td>0.010766</td>\n",
       "      <td>0.022758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025105</td>\n",
       "      <td>0.012996</td>\n",
       "      <td>0.024888</td>\n",
       "      <td>0.048895</td>\n",
       "      <td>0.074420</td>\n",
       "      <td>0.009391</td>\n",
       "      <td>0.042794</td>\n",
       "      <td>0.016054</td>\n",
       "      <td>0.019895</td>\n",
       "      <td>4789644.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.004084</td>\n",
       "      <td>0.023765</td>\n",
       "      <td>0.048214</td>\n",
       "      <td>0.024178</td>\n",
       "      <td>0.056814</td>\n",
       "      <td>0.017431</td>\n",
       "      <td>0.010380</td>\n",
       "      <td>0.022964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.013220</td>\n",
       "      <td>0.026913</td>\n",
       "      <td>0.047038</td>\n",
       "      <td>0.076683</td>\n",
       "      <td>0.009323</td>\n",
       "      <td>0.043304</td>\n",
       "      <td>0.016045</td>\n",
       "      <td>0.024762</td>\n",
       "      <td>4798658.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.004095</td>\n",
       "      <td>0.023397</td>\n",
       "      <td>0.048688</td>\n",
       "      <td>0.023853</td>\n",
       "      <td>0.057210</td>\n",
       "      <td>0.017645</td>\n",
       "      <td>0.009864</td>\n",
       "      <td>0.022423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024978</td>\n",
       "      <td>0.013528</td>\n",
       "      <td>0.028491</td>\n",
       "      <td>0.045471</td>\n",
       "      <td>0.077707</td>\n",
       "      <td>0.008791</td>\n",
       "      <td>0.042795</td>\n",
       "      <td>0.016767</td>\n",
       "      <td>0.024294</td>\n",
       "      <td>4853450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>0.002289</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.003969</td>\n",
       "      <td>0.023390</td>\n",
       "      <td>0.047626</td>\n",
       "      <td>0.024203</td>\n",
       "      <td>0.057061</td>\n",
       "      <td>0.017845</td>\n",
       "      <td>0.009603</td>\n",
       "      <td>0.023007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026078</td>\n",
       "      <td>0.012930</td>\n",
       "      <td>0.027594</td>\n",
       "      <td>0.045203</td>\n",
       "      <td>0.078671</td>\n",
       "      <td>0.009535</td>\n",
       "      <td>0.043238</td>\n",
       "      <td>0.016832</td>\n",
       "      <td>0.023296</td>\n",
       "      <td>4873518.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>0.002333</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.022971</td>\n",
       "      <td>0.046898</td>\n",
       "      <td>0.024450</td>\n",
       "      <td>0.055796</td>\n",
       "      <td>0.017925</td>\n",
       "      <td>0.009688</td>\n",
       "      <td>0.023675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027264</td>\n",
       "      <td>0.013290</td>\n",
       "      <td>0.028188</td>\n",
       "      <td>0.045074</td>\n",
       "      <td>0.080983</td>\n",
       "      <td>0.009510</td>\n",
       "      <td>0.043279</td>\n",
       "      <td>0.014476</td>\n",
       "      <td>0.022744</td>\n",
       "      <td>4923370.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.003915</td>\n",
       "      <td>0.024268</td>\n",
       "      <td>0.046502</td>\n",
       "      <td>0.024234</td>\n",
       "      <td>0.055844</td>\n",
       "      <td>0.018095</td>\n",
       "      <td>0.009127</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027306</td>\n",
       "      <td>0.014078</td>\n",
       "      <td>0.028120</td>\n",
       "      <td>0.044949</td>\n",
       "      <td>0.081179</td>\n",
       "      <td>0.009523</td>\n",
       "      <td>0.043436</td>\n",
       "      <td>0.014231</td>\n",
       "      <td>0.022563</td>\n",
       "      <td>4987598.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>0.002365</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.003790</td>\n",
       "      <td>0.024045</td>\n",
       "      <td>0.046496</td>\n",
       "      <td>0.024089</td>\n",
       "      <td>0.055597</td>\n",
       "      <td>0.018309</td>\n",
       "      <td>0.009048</td>\n",
       "      <td>0.022389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028155</td>\n",
       "      <td>0.013789</td>\n",
       "      <td>0.028790</td>\n",
       "      <td>0.044622</td>\n",
       "      <td>0.081091</td>\n",
       "      <td>0.008990</td>\n",
       "      <td>0.044191</td>\n",
       "      <td>0.014258</td>\n",
       "      <td>0.022406</td>\n",
       "      <td>5054550.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CNS01     CNS02     CNS03     CNS04     CNS05     CNS06     CNS07  \\\n",
       "year                                                                         \n",
       "2002  0.002214  0.000815  0.002977  0.029126  0.066438  0.024014  0.059542   \n",
       "2003  0.002143  0.000794  0.003595  0.029779  0.062631  0.024227  0.060253   \n",
       "2004  0.002089  0.000872  0.003779  0.030579  0.061847  0.023821  0.059886   \n",
       "2005  0.002073  0.000967  0.003718  0.030207  0.060359  0.024129  0.060376   \n",
       "2006  0.002248  0.000990  0.003731  0.031113  0.059094  0.023987  0.059462   \n",
       "2007  0.002255  0.000995  0.003794  0.030466  0.058213  0.024117  0.058404   \n",
       "2008  0.002062  0.000968  0.003911  0.030224  0.056498  0.024501  0.056552   \n",
       "2009  0.002126  0.000869  0.004176  0.026922  0.051365  0.024199  0.056787   \n",
       "2010  0.002160  0.000878  0.004084  0.023765  0.048214  0.024178  0.056814   \n",
       "2011  0.002262  0.000850  0.004095  0.023397  0.048688  0.023853  0.057210   \n",
       "2012  0.002289  0.000841  0.003969  0.023390  0.047626  0.024203  0.057061   \n",
       "2013  0.002333  0.000832  0.003937  0.022971  0.046898  0.024450  0.055796   \n",
       "2014  0.002396  0.000774  0.003915  0.024268  0.046502  0.024234  0.055844   \n",
       "2015  0.002365  0.000774  0.003790  0.024045  0.046496  0.024089  0.055597   \n",
       "\n",
       "         CNS08     CNS09     CNS10     ...         CNS12     CNS13     CNS14  \\\n",
       "year                                   ...                                     \n",
       "2002  0.018926  0.012742  0.021497     ...      0.023216  0.010373  0.023933   \n",
       "2003  0.019748  0.012392  0.022015     ...      0.022931  0.012721  0.025218   \n",
       "2004  0.018807  0.012131  0.022019     ...      0.023166  0.013446  0.025802   \n",
       "2005  0.018847  0.012039  0.021825     ...      0.023356  0.014084  0.026300   \n",
       "2006  0.019270  0.011451  0.023058     ...      0.024163  0.013953  0.027102   \n",
       "2007  0.018785  0.011228  0.023187     ...      0.024479  0.013815  0.026339   \n",
       "2008  0.018773  0.010595  0.022476     ...      0.025442  0.013248  0.026728   \n",
       "2009  0.018268  0.010766  0.022758     ...      0.025105  0.012996  0.024888   \n",
       "2010  0.017431  0.010380  0.022964     ...      0.024800  0.013220  0.026913   \n",
       "2011  0.017645  0.009864  0.022423     ...      0.024978  0.013528  0.028491   \n",
       "2012  0.017845  0.009603  0.023007     ...      0.026078  0.012930  0.027594   \n",
       "2013  0.017925  0.009688  0.023675     ...      0.027264  0.013290  0.028188   \n",
       "2014  0.018095  0.009127  0.022692     ...      0.027306  0.014078  0.028120   \n",
       "2015  0.018309  0.009048  0.022389     ...      0.028155  0.013789  0.028790   \n",
       "\n",
       "         CNS15     CNS16     CNS17     CNS18     CNS19     CNS20  total_jobs  \n",
       "year                                                                          \n",
       "2002  0.046984  0.062630  0.007909  0.039876  0.015452  0.023450   4695410.0  \n",
       "2003  0.044066  0.063108  0.009668  0.040764  0.016282  0.019892   4681788.0  \n",
       "2004  0.043614  0.064427  0.009616  0.041618  0.016156  0.018608   4700472.0  \n",
       "2005  0.043390  0.064329  0.009648  0.042061  0.016181  0.018433   4775130.0  \n",
       "2006  0.043303  0.063936  0.009594  0.042197  0.015764  0.018189   4828898.0  \n",
       "2007  0.044716  0.066542  0.009325  0.042039  0.015449  0.018436   4917960.0  \n",
       "2008  0.045883  0.068324  0.009260  0.042603  0.015746  0.018762   4974028.0  \n",
       "2009  0.048895  0.074420  0.009391  0.042794  0.016054  0.019895   4789644.0  \n",
       "2010  0.047038  0.076683  0.009323  0.043304  0.016045  0.024762   4798658.0  \n",
       "2011  0.045471  0.077707  0.008791  0.042795  0.016767  0.024294   4853450.0  \n",
       "2012  0.045203  0.078671  0.009535  0.043238  0.016832  0.023296   4873518.0  \n",
       "2013  0.045074  0.080983  0.009510  0.043279  0.014476  0.022744   4923370.0  \n",
       "2014  0.044949  0.081179  0.009523  0.043436  0.014231  0.022563   4987598.0  \n",
       "2015  0.044622  0.081091  0.008990  0.044191  0.014258  0.022406   5054550.0  \n",
       "\n",
       "[14 rows x 21 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wac_year_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also specially interested in the specific region of Kansas City, MO. Let's take a look at the crosswalk file and identify what geography is most relevant. \n",
    "\n",
    "After looking at the documentation, the unique Place Code and Place Name seems to best delimit Kansas City, MO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "xwalk_kcmo = xwalk[xwalk['stplcname']==\"Kansas City city, MO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tabblk2010</th>\n",
       "      <th>st</th>\n",
       "      <th>stusps</th>\n",
       "      <th>stname</th>\n",
       "      <th>cty</th>\n",
       "      <th>ctyname</th>\n",
       "      <th>trct</th>\n",
       "      <th>trctname</th>\n",
       "      <th>bgrp</th>\n",
       "      <th>bgrpname</th>\n",
       "      <th>...</th>\n",
       "      <th>stanrcname</th>\n",
       "      <th>necta</th>\n",
       "      <th>nectaname</th>\n",
       "      <th>mil</th>\n",
       "      <th>milname</th>\n",
       "      <th>stwib</th>\n",
       "      <th>stwibname</th>\n",
       "      <th>blklatdd</th>\n",
       "      <th>blklondd</th>\n",
       "      <th>createdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12001</td>\n",
       "      <td>12001</td>\n",
       "      <td>12001</td>\n",
       "      <td>12001</td>\n",
       "      <td>12001</td>\n",
       "      <td>12001</td>\n",
       "      <td>12001</td>\n",
       "      <td>12001</td>\n",
       "      <td>12001</td>\n",
       "      <td>12001</td>\n",
       "      <td>...</td>\n",
       "      <td>12001</td>\n",
       "      <td>12001</td>\n",
       "      <td>12001</td>\n",
       "      <td>12001</td>\n",
       "      <td>12001</td>\n",
       "      <td>12001</td>\n",
       "      <td>12001</td>\n",
       "      <td>12001</td>\n",
       "      <td>12001</td>\n",
       "      <td>12001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>12001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>459</td>\n",
       "      <td>459</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11981</td>\n",
       "      <td>11966</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>290950155002083</td>\n",
       "      <td>29</td>\n",
       "      <td>MO</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>29095</td>\n",
       "      <td>Jackson County, MO</td>\n",
       "      <td>29095015500</td>\n",
       "      <td>155 (Jackson, MO)</td>\n",
       "      <td>290950155002</td>\n",
       "      <td>2 (Tract 155, Jackson, MO)</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>99999</td>\n",
       "      <td>nan</td>\n",
       "      <td>9999999999999999999999</td>\n",
       "      <td>nan</td>\n",
       "      <td>29290003</td>\n",
       "      <td>003 Kansas City Vicinity Region WIB</td>\n",
       "      <td>39.0040916</td>\n",
       "      <td>-94.5382808</td>\n",
       "      <td>20170919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>12001</td>\n",
       "      <td>12001</td>\n",
       "      <td>12001</td>\n",
       "      <td>8583</td>\n",
       "      <td>8583</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>...</td>\n",
       "      <td>12001</td>\n",
       "      <td>12001</td>\n",
       "      <td>12001</td>\n",
       "      <td>11985</td>\n",
       "      <td>11985</td>\n",
       "      <td>12001</td>\n",
       "      <td>12001</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             tabblk2010     st stusps    stname    cty             ctyname  \\\n",
       "count             12001  12001  12001     12001  12001               12001   \n",
       "unique            12001      1      1         1      4                   4   \n",
       "top     290950155002083     29     MO  Missouri  29095  Jackson County, MO   \n",
       "freq                  1  12001  12001     12001   8583                8583   \n",
       "\n",
       "               trct           trctname          bgrp  \\\n",
       "count         12001              12001         12001   \n",
       "unique          172                172           459   \n",
       "top     29095015500  155 (Jackson, MO)  290950155002   \n",
       "freq            303                303           248   \n",
       "\n",
       "                          bgrpname    ...     stanrcname  necta nectaname  \\\n",
       "count                        12001    ...          12001  12001     12001   \n",
       "unique                         459    ...              1      1         1   \n",
       "top     2 (Tract 155, Jackson, MO)    ...            nan  99999       nan   \n",
       "freq                           248    ...          12001  12001     12001   \n",
       "\n",
       "                           mil milname     stwib  \\\n",
       "count                    12001   12001     12001   \n",
       "unique                       3       3         1   \n",
       "top     9999999999999999999999     nan  29290003   \n",
       "freq                     11985   11985     12001   \n",
       "\n",
       "                                  stwibname    blklatdd     blklondd  \\\n",
       "count                                 12001       12001        12001   \n",
       "unique                                    1       11981        11966   \n",
       "top     003 Kansas City Vicinity Region WIB  39.0040916  -94.5382808   \n",
       "freq                                  12001           2            3   \n",
       "\n",
       "       createdate  \n",
       "count       12001  \n",
       "unique          1  \n",
       "top      20170919  \n",
       "freq        12001  \n",
       "\n",
       "[4 rows x 43 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xwalk_kcmo.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice above that Kansas City, MO, is made up of:\n",
    "\n",
    "- 12001 blocks (`tabblk2010`)\n",
    "- 4 counties (`cty`)\n",
    "- 62 zip codes (`zcta`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #FFFF00\"> add something similar for water </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 3: Combine datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the LODES data gives interesting information about the distribution of jobs by industry at block level over the entire Missouri state, we would like to restrict our analysis to the city of Kansas City. Unfortunately there is no metropolitan area information on the LODES dataset. The only way of restricting to Kansas City is to first merge on the geographic information from the crosswalk file.\n",
    "\n",
    "The following SQL query will directly merge on the relevant geographic information, and restrict to the value of interest (where `stplcname` is \"Kansas City city, MO\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# query = '''\n",
    "# SELECT\n",
    "#     a.*\n",
    "#     , b.tabblk2010\n",
    "#     , b.cty\n",
    "#     , b.ctyname\n",
    "#     , b.stplc\n",
    "#     , b.stplcname\n",
    "# FROM mo_wac AS a\n",
    "# LEFT JOIN mo_xwalk AS b\n",
    "# ON a.w_geocode = b.tabblk2010\n",
    "# WHERE stplc = \"Kansas City city, MO\";\n",
    "# '''\n",
    "\n",
    "# wac_kcmo = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP:\n",
    "wac_kcmo = pd.merge(wac, xwalk[['tabblk2010', 'cty', 'ctyname', 'stplc', 'stplcname']], how = 'left'\n",
    "                    , left_on = 'w_geocode', right_on = 'tabblk2010')\n",
    "wac_kcmo = wac_kcmo[wac_kcmo['stplcname'] == \"Kansas City city, MO\"].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can conduct the same analysis as before on the the area of Kansas City, MO.\n",
    "\n",
    "<span style=\"background-color: #FFFF00\"> TO DO </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Comparing Variables from different Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #FFFF00\"> TO DO with water data or wage records </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "### Step 1: Looking for datasets, variables of interest\n",
    "\n",
    "In the LODES data:\n",
    "- Overall Jobs\n",
    "    - See variable `C000` for total jobs by Census Block.\n",
    "- Worker Classification:\n",
    "    - Total job count is split by worker age (`CA01` to `CA03`), worker wage (`CE01` to `CE03`), worker race (`CR01` to `CR05`), worker ethnicity (`CT01` to `CT02`), worker education (`CD01` to `CD04`), and worker sex (`CS01` to `CS02`).\n",
    "- Industry Classification:\n",
    "    - The number of jobs by NAICS (North American Industry Classification System) Codes are given in variables `CNS01` to `CNS20`.\n",
    "    - *Some NAICS Codes are grouped together when they refer to a same sector (codes 31 to 33 all are all manufacturing codes, for example)*\n",
    "    - Look in the ADRF for the <span style=\"background-color: #FFFF00\">*2007 North American Industry Classification System (NAICS) Definitions data file* </span>. We have the mapping of variables `CNS01` to `CNS20` to the NAICS classification code.\n",
    "- Year Variable\n",
    "    - See `year` variable.\n",
    "- Geography\n",
    "    - The `w_geocode` is the workplace Census Block Code. \n",
    "    \n",
    "In order to map the Census Block Code to larger geographic areas, a crosswalk table is also provided (`mo_xwalk`). The has been mapped to:\n",
    "- state level (`st`, `stusps`, `stname`)\n",
    "- county level (`cty`, `ctyname`)\n",
    "- metropolitan area level (`cbsa`, `cbsaname`)\n",
    "- zipcode (`zcta`)\n",
    "\n",
    "       \n",
    "### Step 2: Getting/Creating relevant data tables\n",
    "- [DATA A](#DATA-A): Identify how many blocks in the Kansas City, MO, metropolitan area had jobs in 2017. In which block were there the highest number of jobs?\n",
    "- [DATA B](#DATA-B): What NAICS Industry Code employed the most people in 2017?\n",
    "\n",
    "\n",
    "- [DATA C](#DATA-C): Getting a random sample of 10,000 rows from wage data\n",
    "- [DATA D](#DATA-D): Matching DATA A and DATA C\n",
    "- [DATA E](#DATA-E): MATCHING Data D HH_Member data to subset information only for head of households\n",
    "- [DATA F](#DATA-F): Comparing avergae wages across sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA A\n",
    "- back to [Steps](#Step-1:-Looking-for-the-variables-of-interest-in-the-LODES-data)\n",
    "\n",
    "Getting a list of all employers in manufacturing industries in 2010. We will use the dataset \"ides.il_qcew_employers\" for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate SQL\n",
    "sql_string = \"CREATE table if not exists \" + output_schema + \".\" + table_unique_prefix + \"naics_2010 as\"\n",
    "sql_string += \" SELECT DISTINCT empr_no, seinunit, ein, name_legal, auxiliary_naics \"\n",
    "#chosen the variables of interest\n",
    "sql_string += \" from ides.il_qcew_employers \"\n",
    "sql_string += \" where substr(auxiliary_naics,1,2) in ('31', '32', '33')\"\n",
    "#subset the data to contain only those values whose naics value starts from 31, 32 or 33\n",
    "sql_string += \" and year=2010 and quarter=1\"\n",
    "#subset the data for the time period of interest\n",
    "sql_string += \";\"\n",
    "#this seim-colon is not necessary in psycopg2 but it is widely used across SQL supporting programs. \n",
    "\n",
    "# execute it.\n",
    "pgsql_cursor.execute(sql_string)\n",
    "pgsql_connection.commit()\n",
    "\n",
    "print( \"TABLE NAICS_2010 created on \" + str( datetime.datetime.now() ) )\n",
    "\n",
    "#Rollback query below if you need it\n",
    "#pgsql_connection.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now that we created our table, let us look at some of the top rows\n",
    "#generating read SQL\n",
    "sql_string1 = \"select * from \" + output_schema +  \".\" + table_unique_prefix + \"naics_2010 limit 10\"\n",
    "#since we gave a limit 10 option in our query, it is not necessary to use the head command below\n",
    "#(unless you want to see fewer than 10 rows)\n",
    "\n",
    "# read it\n",
    "r = pd.read_sql(sql_string1, con=pgsql_connection)\n",
    "r.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#It is likely that you will see that some employers do not have a legal name. \n",
    "#While not necessary for this aggregate analysis- this might be a question of interest before proceeding. \n",
    "\n",
    "\n",
    "#Let us find how many employers do not have a legal name?\n",
    "\n",
    "#generating read SQL\n",
    "sql_string2 = \"select count(distinct empr_no) from \" + output_schema + \".\" +  table_unique_prefix + \"naics_2010 \" \n",
    "sql_string2+= \" WHERE name_legal in ('nan', '.', '') \"\n",
    "# read it\n",
    "r = pd.read_sql(sql_string2, con=pgsql_connection)\n",
    "r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#It is important to see how many total number of employers are there in the data. \n",
    "#This is to take the value of missing legal names into 'statistical perspective'\n",
    "\n",
    "#generating read SQL\n",
    "sql_string3 = \"select count(distinct empr_no) from \" + output_schema + \".\" + table_unique_prefix + \"naics_2010 \"\n",
    "\n",
    "# read it\n",
    "r = pd.read_sql(sql_string3, con=pgsql_connection)\n",
    "r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values\n",
    "\n",
    "- XXX of our data has missing legal names\n",
    "- A good rule of thumb is that we can drop data with missing values if missing values is less than 5% of the data. \n",
    "    - However, in this case: \n",
    "     - a) our variable of interest 'name_legal' is not important to us\n",
    "     - b) and missing values are very high\n",
    "\n",
    "**So we will not drop the data**\n",
    "\n",
    "*An alternative and probably better way to see if the employers with no legal names can be dropped is to see the below: \n",
    "    1. what percentage of employees work in these firms\n",
    "    2. how many wages are earned by the employees working with these employers\n",
    "This will again be only necessary if we care about this variable to begin with. \n",
    "Since this is an aggregate level study- we do not care about individual employers or their names. \n",
    "However, it could have been a variable of interest in some other study*\n",
    "\n",
    "- We could have done the same analysis for other variables of interest also such as: \n",
    "    - seinunit or ein\n",
    "    - naics (but it will not be missing since we subsetted our data for manufacturing codes initially)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USING A CONDITION STATEMENT IN SQL\n",
    "\n",
    "##### Of interest: If an employer has a legal name or not\n",
    "#### SQL QUERIES USED: \n",
    "    * CASE WHEN\n",
    "    * GROUP BY\n",
    "    * SUM\n",
    "    * OVER\n",
    "    * DISTINCT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##WE COULD HAVE DONE THE SAME THING IN ONE QUERY ALSO\n",
    "#Calculating the percentage of employers having a legal name vs the ones not\n",
    "\n",
    "#CREATING AN ID with a CONDITION STATEMENT (CALLED CASE in SQL)\n",
    "sql_string3 = \"select case when name_legal in ('nan', '.', '') then 1 else 2 end as name_type, \"\n",
    "#Creating an ID with a value of 1 if name_legal is missing and a value of 2 if not missing\n",
    "sql_string3 += \"count(distinct empr_no), \"\n",
    "#Counting the distinct number of employers associated with both IDs\n",
    "sql_string3 += \"count(distinct empr_no)/(sum(count(distinct empr_no)) over()) PER \"\n",
    "#Counting the percentage of values in both IDs\n",
    "sql_string3 += \"from \" + output_schema + \".\" + table_unique_prefix + \"naics_2010 \" \n",
    "#SPECIFYING THE BASE TABLE\n",
    "sql_string3 += \" group by name_type \"\n",
    "#GROUPING THE SUM for both ID\n",
    "\n",
    "# read it\n",
    "r = pd.read_sql(sql_string3, con=pgsql_connection)\n",
    "r\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP-2; DATA-B\n",
    "\n",
    "Getting a list of all employees and their wage earnings for first quarter in 2010 from \"ides.il_wage\"\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)\n",
    "- back to [Analysis](#Analysis)\n",
    "- back to [STEPS](#STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#STEP 2- DATA B\n",
    "#DATA B: Getting a list of all employees and their wage earnings for first quarter in 2010 from \"ides.il_wage\"\n",
    "\n",
    "# generate SQL\n",
    "sql_string = \"CREATE table if not exists \" + output_schema + \".\" + table_unique_prefix + \"employee_2010 as\"\n",
    "sql_string += \" SELECT DISTINCT ssn, empr_no, seinunit, ein, wage, hours, weeks\"\n",
    "sql_string += \" from ides.il_wage \"\n",
    "sql_string += \" where year=2010 and quarter=1\"\n",
    "sql_string += \";\"\n",
    "\n",
    "\n",
    "# execute it.\n",
    "pgsql_cursor.execute(sql_string)\n",
    "pgsql_connection.commit()\n",
    "\n",
    "print( \"TABLE employee_2010 created on \" + str( datetime.datetime.now() ) )\n",
    "\n",
    "#pgsql_cursor.execute(\"drop table data_prep.naics_2010\")\n",
    "# pgsql_connection.commit()\n",
    "\n",
    "#pgsql_connection.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#looking at our data\n",
    "#generating read SQL\n",
    "sql_string2 = \"select * from \" + output_schema + \".\" + table_unique_prefix + \"employee_2010\"\n",
    "#sql_string2 += \" limit 10\"\n",
    "\n",
    "# read it\n",
    "r = pd.read_sql(sql_string2, con=pgsql_connection)\n",
    "r.head(5)\n",
    "#You can test the time taken to run this query by using the limit option vs not using. \n",
    "#While the limit option will lead to the query reading only 10 rows, \n",
    "#not using it will lead the query reading all of the rows- yet, reporting only 5 \n",
    "\n",
    "#It is always better to use the limit option if we know we are not interested in reading the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#looking at #employees\n",
    "#generating read SQL\n",
    "sql_string3 = \"select count(distinct ssn) from \" + output_schema + \".\" + table_unique_prefix + \"employee_2010\"\n",
    "# read it\n",
    "r = pd.read_sql(sql_string3, con=pgsql_connection)\n",
    "r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql_string3 = \"select count(*) from \" + output_schema + \".\" + table_unique_prefix + \"employee_2010\"\n",
    "r = pd.read_sql(sql_string3, con=pgsql_connection)\n",
    "r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#looking at employees with non-missing wages\n",
    "\n",
    "sql_string4 = \"select count(distinct ssn) from \" + output_schema + \".\" + table_unique_prefix + \"employee_2010\"+ \" where wage>0\"\n",
    "r = pd.read_sql(sql_string4, con=pgsql_connection)\n",
    "r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### STEP-2; DATA-C\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)\n",
    "- back to [Analysis](#Analysis)\n",
    "- back to [STEPS](#STEPS)\n",
    "\n",
    "__SQL QUERY - taking a random sample__\n",
    "\n",
    "We want to take a random subset of 10,000 employees to shorten the running time of this query. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Taking a random sample of employees\n",
    "\n",
    "\n",
    "sql_string = \"CREATE TABLE if not exists \" + output_schema + \".\" + table_unique_prefix + \"emp_2010_random as\"\n",
    "sql_string += \" select * from \" + output_schema + \".\" + table_unique_prefix + \"employee_2010\"\n",
    "sql_string += \" ORDER BY RANDOM()  \"\n",
    "sql_string += \" LIMIT 10000\"\n",
    "\n",
    "\n",
    "#we use distinct function so we only get unique rows\n",
    "# execute it.\n",
    "pgsql_cursor.execute(sql_string)\n",
    "pgsql_connection.commit()\n",
    "\n",
    "print( \"TABLE emp_2010_random created on \" + str( datetime.datetime.now() ) )\n",
    "#pgsql_connection.rollback()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TESTING IF THIS IS INDEED 1000 rows\n",
    "\n",
    "\n",
    "sql_string = \"select count(*) from \" + output_schema + \".\" + table_unique_prefix + \"emp_2010_random\"\n",
    "\n",
    "#we use distinct function so we only get unique rows\n",
    "# execute it.\n",
    "pgsql_cursor.execute(sql_string)\n",
    "pgsql_connection.commit()\n",
    "\n",
    "r = pd.read_sql(sql_string, con=pgsql_connection)\n",
    "r\n",
    "#pgsql_connection.rollback()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pgsql_connection.rollback()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP-2; DATA-D\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)\n",
    "- back to [Analysis](#Analysis)\n",
    "- back to [STEPS](#STEPS)\n",
    "\n",
    "__SQL QUERY -  Matching the Data__\n",
    "- LEFT JOIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#STEP 2- DATA D\n",
    "#DATA D: MATCHING DATA A & DATA B--- to get a list of employees who are working in manufacturing industry\n",
    "\n",
    "sql_string = \"CREATE TABLE if not exists \" + output_schema + \".\" +  table_unique_prefix + \"emp_manuf as\"\n",
    "sql_string += \" select distinct a.name_legal, a.auxiliary_naics, b.* from \" + output_schema + \".\" + table_unique_prefix + \"naics_2010 as a\"\n",
    "sql_string += \" LEFT JOIN \" + output_schema + \".\" + table_unique_prefix + \"emp_2010_random as b\"  \n",
    "sql_string += \" on a.empr_no=b.empr_no \"\n",
    "sql_string += \" and a.seinunit=b.seinunit \"\n",
    "sql_string += \" and a.ein=b.ein\"\n",
    "\n",
    "#we use distinct function so we only get unique rows\n",
    "# execute it.\n",
    "pgsql_cursor.execute(sql_string)\n",
    "pgsql_connection.commit()\n",
    "\n",
    "print( \"TABLE emp_manuf created on \" + str( datetime.datetime.now() ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sql_string = \"select * from \" + output_schema + \".\" + table_unique_prefix + \"EMP_MANUF\"+ \" LIMIT 1\"\n",
    "# r = pd.read_sql(sql_string, con=pgsql_connection)\n",
    "# r\n",
    "\n",
    "sql_string = \"select count(*), count(distinct ssn) from \" + output_schema + \".\" + table_unique_prefix + \"EMP_MANUF\"\n",
    "r = pd.read_sql(sql_string, con=pgsql_connection)\n",
    "r\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP-2; DATA-E-1\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)\n",
    "- back to [Analysis](#Analysis)\n",
    "- back to [STEPS](#STEPS)\n",
    "\n",
    "__SQL QUERY- __\n",
    "- CASE WHEN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#STEP 2- DATA E-1\n",
    "#DATA E-1: Preparing the HH_MEMBER data\n",
    "\n",
    "sql_string = \"CREATE TABLE if not exists \" + output_schema + \".\" + table_unique_prefix + \"hh_mem0 as\"\n",
    "sql_string += \" select distinct ssn_hash, rootrace, ssnind ,sex\"\n",
    "sql_string += \" from idhs.hh_member \"  \n",
    "\n",
    "# execute it.\n",
    "pgsql_cursor.execute(sql_string)\n",
    "pgsql_connection.commit()\n",
    "\n",
    "print( \"TABLE hh_mem0 created on \" + str( datetime.datetime.now() ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Counting number of distinct SSN vs number of rows in this data\n",
    "\n",
    "sql_string = \"select count(*), count(distinct ssn_hash) from \" + output_schema + \".\" + table_unique_prefix + \"hh_mem0\"\n",
    "r = pd.read_sql(sql_string, con=pgsql_connection)\n",
    "r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pgsql_connection.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "sql_string  = \"CREATE TABLE if not exists \" + output_schema + \".\" + table_unique_prefix + \"hh_mem1 as\"\n",
    "sql_string += \" select ssn_hash,  count(*) as cnt \"\n",
    "sql_string += \"from \" + output_schema + \".\" + table_unique_prefix + \"hh_mem0 group by ssn_hash\"\n",
    "sql_string += \" order by cnt desc \"\n",
    "\n",
    "# execute it.\n",
    "pgsql_cursor.execute(sql_string)\n",
    "pgsql_connection.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading the newly created table\n",
    "sql_string=\"select * from \" + output_schema + \".\"  + ind + \"hh_mem1 limit 5\"\n",
    "s = pd.read_sql(sql_string, con=pgsql_connection)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating a sub table which has unique rows for each ssn\n",
    "sql_string  = \"Select cnt, count(*) as cnt,\"\n",
    "sql_string += \" 100*(count(*)/(sum(count(*)) over())) as per\" \n",
    "sql_string += \" from \"+ output_schema + \".\" + table_unique_prefix + \"hh_mem1\"\n",
    "sql_string += \" group by cnt\"\n",
    "s = pd.read_sql(sql_string, con=pgsql_connection)\n",
    "s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#STEP 2- DATA E-1\n",
    "#DATA E-1: Creating the subsetted data table for hh_member which is cleaned to maintain one unique row per individual\n",
    "\n",
    "sql_string = \"CREATE TABLE if not exists \" + output_schema + \".\" + table_unique_prefix + \"hh_mem2 as\"\n",
    "sql_string += \" select distinct ssn_hash, rootrace, ssnind ,sex\"\n",
    "sql_string += \" from \" + output_schema + \".\" + table_unique_prefix + \"hh_mem0 \"  \n",
    "sql_string += \" where ssn_hash in \"\n",
    "sql_string += \" (select ssn_hash from \" + output_schema + \".\" + table_unique_prefix + \"hh_mem1\"\n",
    "sql_string += \" where cnt=1) \"\n",
    "\n",
    "# execute it.\n",
    "pgsql_cursor.execute(sql_string)\n",
    "pgsql_connection.commit()\n",
    "\n",
    "print( \"TABLE hh_mem2 created on \" + str( datetime.datetime.now() ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pgsql_connection.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP-2; DATA-E-2\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)\n",
    "- back to [Analysis](#Analysis)\n",
    "- back to [STEPS](#STEPS)\n",
    "\n",
    "__SQL QUERY-  Matching the Data__\n",
    "- INNER JOIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#STEP 2- DATA E-2\n",
    "#DATA E: MATCHING DATA WITH HH_MEMBERS\n",
    "#WE only want information for head of households\n",
    "\n",
    "#You can use the base data hh_mem0 as well which has not been cleaned. \n",
    "#The only difference is that then you will not be able to use the summary measure 'avg' as explained further\n",
    "#keep reading!\n",
    "\n",
    "match_table= \"hh_mem2\"\n",
    "#match_table= \"hh_mem0\"\n",
    "\n",
    "\n",
    "sql_string = \"CREATE TABLE if not exists \" + output_schema + \".\" + table_unique_prefix + \"emp_manuf\" + \"_\" +match_table+ \" as\"\n",
    "sql_string += \" select a.*, b.ssn_hash, b.rootrace, b.ssnind , b.sex\"\n",
    "sql_string += \" from \" + output_schema + \".\" + table_unique_prefix + \"emp_manuf as a\"  \n",
    "sql_string += \" inner join \"  + output_schema + \".\" + table_unique_prefix + match_table  +  \" as b\"  \n",
    "sql_string += \" on a.ssn=b.ssn_hash\"\n",
    "\n",
    "# execute it.\n",
    "pgsql_cursor.execute(sql_string)\n",
    "pgsql_connection.commit()\n",
    "\n",
    "print( \"TABLE emp_manuf_hh created on \" + str( datetime.datetime.now() ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of employees\n",
    "sql_string = \"select count(*) as cnt_rows, count(distinct ssn) as cnt_ind from \" + output_schema + \".\" + table_unique_prefix + \"emp_manuf\" + \"_\" +match_table\n",
    "r = pd.read_sql(sql_string, con=pgsql_connection)\n",
    "r\n",
    "\n",
    "#If you match the above data with hh_mem0 (not cleaned), you will get ## records for ## employees. \n",
    "#If you match the above data with hh_mem2 (cleaned), you will get ## records for ##-X employees. \n",
    "\n",
    "# sql_string = \"select * from \" + output_schema + \".\" + ind + \"EMP_MANUF_HH LIMIT 2\"\n",
    "# s = pd.read_sql(sql_string, con=pgsql_connection)\n",
    "# s\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP-2; DATA-F\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)\n",
    "- back to [Analysis](#Analysis)\n",
    "- back to [STEPS](#STEPS)\n",
    "\n",
    "__Getting aggregate measures by SEX__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#STEP 2- DATA F\n",
    "#DATA F: Aggregating data - by sex\n",
    "#WE only want information for head of households\n",
    "\n",
    "\n",
    "match_table= \"hh_mem2\"\n",
    "#match_table= \"hh_mem0\"\n",
    "\n",
    "sql_string = \"CREATE TABLE if not exists \" + output_schema + \".\" + table_unique_prefix + \"emp_manuf_hh_Sex as\"\n",
    "sql_string += \" select sex, count(distinct ssn) as cnt, sum(wage) as sum, \"\n",
    "sql_string += \"100*(count(distinct ssn)/sum(count(distinct ssn)) over()) as per_cnt, \"\n",
    "sql_string += \"100*(sum(wage)/ (sum(sum(wage)) over())) as per_wage\"\n",
    "\n",
    "sql_string += \" from \" + output_schema + \".\" + table_unique_prefix + \"emp_manuf_\" + match_table + \" group by sex;\"\n",
    "\n",
    "\n",
    "#group by ssn, rootrace, sex\n",
    "# execute it.\n",
    "pgsql_cursor.execute(sql_string)\n",
    "pgsql_connection.commit()\n",
    "\n",
    "print( \"TABLE emp_manuf_hh created on\" + str( datetime.datetime.now() ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reading the data\n",
    "\n",
    "#sql_string = \"DROP TABLE \" + output_schema + \".\" + ind + \"EMP_MANUF_HH_Sex \"\n",
    "\n",
    "sql_string = \"select * from \" + output_schema + \".\" + table_unique_prefix + \"EMP_MANUF_HH_Sex \"\n",
    "s = pd.read_sql(sql_string, con=pgsql_connection)\n",
    "s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Calculating average wages for each gender group\n",
    "\n",
    "sql_string = \"select sex, sum/cnt as avg_wage  from \" + output_schema + \".\" + table_unique_prefix + \"EMP_MANUF_HH_Sex  \"\n",
    "s = pd.read_sql(sql_string, con=pgsql_connection)\n",
    "s\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using summary queries in SQL\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)\n",
    "- back to [Analysis](#Analysis)\n",
    "- back to [STEPS](#STEPS)\n",
    "\n",
    "__When to use these instead:__\n",
    "\n",
    "Instead of actually calculating the average, we can rely on some simple SQL queries to compute mean measures. \n",
    "\n",
    "- Since we cleaned our data to have one row per individual- we can also rely on a simple SQL query 'average' to calculate average wages by any variable of interest. \n",
    "- However, if we had not cleaned our data-- then it will have to be necessary to actually 'calculate'- since SQL will take the number of rows- and not the number of distinct individuals (ssn) to calculate averages. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ALTERNATIVE and QUICKER WAY TO DO THIS\n",
    "\n",
    "sql_string = \"select sex, count(distinct ssn) as ind_cnt, \"\n",
    "sql_string += \"avg(wage)  from \" + output_schema + \".\" + table_unique_prefix + \"EMP_MANUF_HH group by sex \"\n",
    "s = pd.read_sql(sql_string, con=pgsql_connection)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#OTHER SUMMARY MEASURES\n",
    "\n",
    "sql_string = \"select rootrace, count(distinct ssn) as ind_cnt, avg(wage) avg from \" + output_schema + \".\" + table_unique_prefix + \"EMP_MANUF_HH group by rootrace order by avg \"\n",
    "s = pd.read_sql(sql_string, con=pgsql_connection)\n",
    "s\n",
    "\n",
    "#  1=White, not of Hispanic origin, \n",
    "#  2=Black, not of Hispanic origin, \n",
    "#  3=American Indian or Alaskan Native, \n",
    "#  6=Hispanic (includes Mexican, Puerto Rican, Cuban, and Other South American), \n",
    "#  7=Asian or Pacific Islander (includes Indo-Chinese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting to know the IDHS database\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)\n",
    "- back to [Analysis](#Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Looking at the variables of interest\n",
    "\n",
    "# generate SQL\n",
    "sql_string = \" SELECT * \"\n",
    "sql_string += \" FROM idhs.hh_member\"\n",
    "sql_string += \" LIMIT 10\"\n",
    "sql_string += \";\"\n",
    "\n",
    "# read it\n",
    "r = pd.read_sql(sql_string, con=pgsql_connection)\n",
    "r.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDHS Database\n",
    "## HH_Member table Descrition\n",
    "\n",
    "If you go to the ADRF explorer, and read documentation, you will see what the different variables mean. \n",
    "Here, we paste the description of the variables we will be using for this notebook. \n",
    "\n",
    "1. sex- 1 for male, 2 for female\n",
    "2. rootrace        \n",
    "    - 1=White, not of Hispanic origin, \n",
    "    - 2=Black, not of Hispanic origin, \n",
    "    - 3=American Indian or Alaskan Native, \n",
    "    - 6=Hispanic (includes Mexican, Puerto Rican, Cuban, and Other South American), \n",
    "    - 7=Asian or Pacific Islander (includes Indo-Chinese)\n",
    "3. ssn_hash- hashed SSN\n",
    "4. ssnind- Indicates the validity of the recipient social security number. \n",
    "    - J=Validity unknown, \n",
    "    - K=SSA not in SSA file, \n",
    "    - L=Sex code does not match SSA file,\n",
    "    - M=DOB does not match SSA file, \n",
    "    - N=DOB and sex code do not match SSA file, \n",
    "    - O=Name does not match SSA file (sex code and DOB not checked), \n",
    "    - P=SS5 form is pending with SSA, R=SS5 form is pending with enumeration control, \n",
    "    - V=SS Administration has verified SSN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sql_string1 = \"SELECT sex, count( *) as cnt, count(*)/sum(count(*)) over() as PER from idhs.hh_member group by sex\"\n",
    "# r1 = pd.read_sql(sql_string1, con=pgsql_connection)\n",
    "# print(r1)\n",
    "\n",
    "sql_string2 = \"SELECT ssnind, count( *) as cnt, 100*(count(*)/sum(count(*)) over()) as PER from idhs.hh_member group by ssnind\"\n",
    "r2 = pd.read_sql(sql_string2, con=pgsql_connection)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing by INDEX\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)\n",
    "- back to [Analysis](#Analysis)\n",
    "    \n",
    "We can also print the results of our SQL queries by Column INDEX. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Printing by INDEX\n",
    "\n",
    "# generate SQL\n",
    "sql_string = \" SELECT *\"\n",
    "sql_string += \" FROM idhs.hh_member\"\n",
    "sql_string += \" LIMIT 10\"\n",
    "sql_string += \";\"\n",
    "\n",
    "# execute it.\n",
    "pgsql_cursor.execute(sql_string)\n",
    "pgsql_connection.commit()\n",
    "results=pgsql_cursor.fetchall()\n",
    "\n",
    "#PRINTING BY INDEX\n",
    "\n",
    "print \"\\nShow me the databases:\\n\"\n",
    "for row in results: \n",
    "    print row[1]\n",
    "   #print \"\", row[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Queries\n",
    "\n",
    "- Count of Male & Females within head of household data\n",
    "- Count of Individuals with no wages in a quarter\n",
    "- The maximum wage in a particular industry in a quarter\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Count of Male & Females within head of household data\n",
    "\n",
    "# generate SQL\n",
    "sql_string = \" SELECT sex, count(distinct ssn_hash) as cnt \"\n",
    "sql_string += \" FROM idhs.hh_member\"\n",
    "sql_string += \" group by sex\"\n",
    "sql_string += \";\"\n",
    "\n",
    "# execute it.\n",
    "#pgsql_cursor.execute(sql_string)\n",
    "#pgsql_connection.commit()\n",
    "\n",
    "r2 = pd.read_sql(sql_string, con=pgsql_connection)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Count of Individuals with no wages in a quarter\n",
    "\n",
    "# **LONG QUERY- DO NOT RUN WHILE IN CLASS**\n",
    "year='2010'\n",
    "quarter='2'\n",
    "\n",
    "\n",
    "# generate SQL\n",
    "sql_string = \" SELECT count(distinct ssn) as cnt \"\n",
    "sql_string += \" FROM ides.il_wage\"\n",
    "sql_string += \" where year=\" + year +\"and quarter= \" + quarter\n",
    "sql_string += \" and wage=0\"\n",
    "\n",
    "# execute it.\n",
    "#pgsql_cursor.execute(sql_string)\n",
    "#pgsql_connection.commit()\n",
    "\n",
    "r2 = pd.read_sql(sql_string, con=pgsql_connection)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The maximum wage and min wages in a particular time period\n",
    "\n",
    "\n",
    "# **LONG QUERY- DO NOT RUN WHILE IN CLASS**\n",
    "year='2010'\n",
    "quarter='2'\n",
    "\n",
    "\n",
    "\n",
    "# generate SQL\n",
    "sql_string = \" SELECT min(wage) as min, max(wage) as max \"\n",
    "sql_string += \" FROM ides.il_wage\"\n",
    "sql_string += \" where year=\" + year +\"and quarter= \" + quarter\n",
    "#sql_string += \" and wage>100\"\n",
    "\n",
    "# execute it.\n",
    "#pgsql_cursor.execute(sql_string)\n",
    "#pgsql_connection.commit()\n",
    "\n",
    "r2 = pd.read_sql(sql_string, con=pgsql_connection)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Close Connection and cursor\n",
    "pgsql_cursor.close()\n",
    "pgsql_connection.close()\n",
    "\n",
    "print( \"psycopg2 cursor and connection closed at \" + str( datetime.datetime.now() ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "1072px",
    "left": "324px",
    "top": "193.958px",
    "width": "389px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
