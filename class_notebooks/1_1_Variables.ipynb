{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src=\"images/CI_horizontal.png\" width=\"600\">\n",
    "<center>\n",
    "    <span style=\"font-size: 1.5em;\">\n",
    "        <a href='https://www.coleridgeinitiative.org'>Website</a>\n",
    "    </span>\n",
    "</center>\n",
    "\n",
    "Ghani, Rayid, Frauke Kreuter, Julia Lane, Adrianne Bradford, Alex Engler, Nicolas Guetta Jeanrenaud, Graham Henke, Daniela Hochfellner, Clayton Hunter, Brian Kim, Avishek Kumar, Jonathan Morgan, and Ridhima Sodhi. \"ADA-KCMO-2018.\" Coleridge Initiative GitHub Repositories. 2018. https://github.com/Coleridge-Initiative/ada-kcmo-2018. [![DOI](https://zenodo.org/badge/119078858.svg)](https://zenodo.org/badge/latestdoi/119078858)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables: Analyzing your Datasets\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "    - [Learning Objectives](#Learning-Objectives)\n",
    "    - [Methods](#Methods)\n",
    "- [Python Setup](#Python-Setup)\n",
    "- [Load the Data](#Load-the-Data)\n",
    "    - [Establish a Connection to the Database](#Establish-a-Connection-to-the-Database)\n",
    "    - [Formulate Data Query](#Formulate-Data-Query)\n",
    "    - [Pull Data from the Database](#Pull-Data-from-the-Database)\n",
    "- [Analysis: Using Python and SQL to Analyze Economic Activity in KCMO](#Analysis:-Using-Python-and-SQL-to-Analyze-Economic-Activity-in-KCMO)\n",
    "    - [What is in the Database?](#What-is-in-the-Database?)\n",
    "    - [Summary Statistics on Different Datasets](#Summary-Statistics-on-Different-Datasets)\n",
    "    - [Combining Datasets](#Combining-Datasets)\n",
    "    - [Creating New Measures](#Creating-New-Measures)\n",
    "- [Exercise](#Exercise)\n",
    "- [Submit Results](#Submit-Results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In an ideal world, we will have all of the data we want with all of the desirable properties (no missing values, no errors, standard formats, and so on). \n",
    "However, that is hardly ever true - and we have to work with using our datasets to answer questions of interest as intelligently as possible. \n",
    "\n",
    "In this notebook, we will discover the datasets we have on the ADRF, and we will use our datasets to answer some questions of interest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objectives\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "This notebook will give you the opportunity to spend some hands-on time with the data. \n",
    "\n",
    "You will have an opportunity to explore the different datasets in the ADRF, and this notebook will take you around the different ways you can analyze your data. This involves looking at basic metrics in the larger dataset, taking a random sample, creating derived variables, making sense of the missing values, and so on. \n",
    "\n",
    "This will be done using both SQL and `pandas` in Python. The `psycopg` Python package will give you the opportunity to interact with the database directly in SQL. Some additional manipulations will be handled by Pandas in Python (by converting your datasets into dataframes).\n",
    "\n",
    "After going through this notebook, you will have a good understanding around: \n",
    "\n",
    "- How to create new tables of interest from the larger tables in database\n",
    "- How to decide on the variables of interest\n",
    "- How to quickly look through aggregate metrics before proceeding with analysis\n",
    "- Possible pitfalls\n",
    "- How to handle missing values\n",
    "- How to join newly created tables\n",
    "- How to think about caveats in your final results\n",
    "\n",
    "### Methods\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "We will be using the `psycopg2` Python package to access tables in our class database server - PostgreSQL. \n",
    "\n",
    "To read the results of our queries, we will be using the `pandas` Python package, which has the ability to read tabular data from SQL queries into a pandas DataFrame object. Within `pandas`, we will use various commands:\n",
    "\n",
    "- Subsetting data\n",
    "- `groupby`\n",
    "- `merge`\n",
    "\n",
    "Within SQL, we will use various queries:\n",
    "\n",
    "- `CREATE TABLE`\n",
    "- `SELECT ROWS`\n",
    "- Summing over groups\n",
    "- Counting distinct values of desired variables\n",
    "- Ordering data by chosen variables\n",
    "- Selecting a random sub-sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Setup\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In Python, we `import` packages. The `import` command allows us to use libraries created by others in our own work by \"importing\" them. You can think of importing a library as opening up a toolbox and pulling out a specific tool. Among the most famous Python packages:\n",
    "- `numpy` is short for \"numerical Python\". `numpy` is a lynchpin in Python's scientific computing stack. Its strengths include a powerful *N*-dimensional array object, and a large suite of functions for doing numerical computing. \n",
    "- `pandas` is a library in Python for data analysis that uses the DataFrame object from R which is similiar to a spreedsheet but allows you to do your analysis programaticaly rather than the point-and-click of Excel. It is a lynchpin of the PyData stack.  \n",
    "- `sqlalchemy` is a Python library for interfacing with a PostGreSQL database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general use imports\n",
    "import datetime\n",
    "import glob\n",
    "import inspect\n",
    "import numpy\n",
    "import os\n",
    "import six\n",
    "import warnings\n",
    "import math\n",
    "from itertools import izip\n",
    "\n",
    "# pandas-related imports\n",
    "import pandas as pd\n",
    "\n",
    "# CSV file reading-related imports\n",
    "import csv\n",
    "\n",
    "# database interaction imports\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__When in doubt, use shift + tab to read the documentation of a method.__\n",
    "\n",
    "__The `help()` function provides information on what you can do with a function.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Instead of using pgAdmin or the command line SQL tool directly, we can also carry out SQL queries using Python. But more power of Python and pandas comes from that they can greatly facilitate descriptive statistics of the data, which is rather complicated to do, if not impossible, in SQL per se. Moreover, Python and pandas plus matplotlib packages can create data visualizations that greatly helps data analysis. We will see some of these advantages in the following content.\n",
    "\n",
    "Pandas provides many ways to load data. It allows the user to read the data from a local csv or excel file, or pull the data from a relational database. Since we are working with the relational database appliedda in this course, we will demonstrate how to use pandas to read data from a relational database. For examples to read data from a CSV file, refert to the pandas documentation [Getting Data In/Out](pandas.pydata.org/pandas-docs/stable/10min.html#getting-data-in-out).\n",
    "\n",
    "The function to create a SQL query and put the data into a pandas dataframe (more to come) is `pd.read_sql()`. Just like doing a SQL query from pgAdmin, this function will ask for some information about the database, and what query you would like to run. Let's walk through the example below.\n",
    "\n",
    "In the most simple case, only 2 parameters are required by the `pd.read_sql()` function to pull data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish a Connection to the Database\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "The first parameter is the connection to the database. To create a connection we will use the SQLAlchemy package and tell it which database we want to connect to, just like in pgAdmin. Additional details on creating a connection to the database are provided in the \"Databases\" notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Parameter 1: Connection__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to create a connection to the database, we need to pass the name of the database and host of the database\n",
    "connection_string = \"postgresql://10.10.2.10/appliedda\"\n",
    "conn = sqlalchemy.create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulate Data Query\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "This part is similar to writing a SQL query in pgAdmin. Depending on what data we are interested in, we can use different queries to pull different data. In this example, we will pull all the content of wage_person data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Parameter 2: Query__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT *\n",
    "FROM kcmo_lehd.mo_qcew_employers\n",
    "WHERE year = 2014 AND qtr = 2\n",
    "LIMIT 20\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "- the three quotation marks surrounding the query body is called multi-line string. It is quite handy for writing SQL queries because the new line character will be considered part of the string, instead of breaking the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have defined a variable `query`, we can call it in the code\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull Data from the Database\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Now that we have the two parameters (database connection and query), we can pass them to the `pd.read_sql()` function, and obtain the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we pass the query and the connection to the pd.read_sql() \n",
    "# function and assign the variable `wage` \n",
    "# to the dataframe returned by the function\n",
    "wages = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Using Python and SQL to Analyze Economic Activity in KCMO\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "__What are different measures of economic activity in Kansas City, Missouri?__\n",
    "\n",
    "We will begin with very simple measures and progress to more complex metrics used by experts. In this notebook we will look at job counts by industry, and more.\n",
    "\n",
    "__Other interesting questions we can answer using same/similar datasets__\n",
    "- How many blocks have industry jobs in Kansas City, MO?\n",
    "- To what extent to the different counties that make up Kansas City, MO, differ in job?\n",
    "- Distribution of these jobs by gender, race, age, income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is in the Database?\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In this preliminary step, you will have a chance to discover the datasets in the ADRF that we presented this morning. These include the Census LODES data, Missouri Wage Records, KCMO water services data, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Schemas, Tables, and Columns in database__\n",
    "\n",
    "Let's pull the list of schema names in the database, the list of tables in these schemas and the list of columns in these tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See all available schemas:\n",
    "query = '''\n",
    "SELECT schema_name \n",
    "FROM information_schema.schemata;\n",
    "'''\n",
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT schemaname, tablename\n",
    "FROM pg_tables\n",
    "WHERE schemaname IN ('public', 'kcmo_lehd', 'kcmo_water', 'ada_kcmo')\n",
    "'''\n",
    "\n",
    "tables = pd.read_sql(query, conn)\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can look at column names within tables:\n",
    "query = '''\n",
    "SELECT * \n",
    "FROM information_schema.columns \n",
    "WHERE table_schema = 'kcmo_lehd' AND table_name = 'mo_qcew_employers'\n",
    "'''\n",
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Water Services: Consumption Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT *\n",
    "FROM kcmo_water.ubbchst_consumption_history\n",
    "limit 100;\n",
    "'''\n",
    "mo_water_consumption = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo_water_consumption.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take some time to look at the documentation and understand what the different column names refer to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Missouri LEHD Records Employer Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT *\n",
    "FROM kcmo_lehd.mo_qcew_employers\n",
    "limit 100;\n",
    "'''\n",
    "mo_qcew_employers = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo_qcew_employers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, take some time to look at the documentation and understand what the different variables refer to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some employer names seem to be missing. Let's see how many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is likely that you will see that some employers do not have a legal name. Let's find how many.\n",
    "\n",
    "#generating read SQL\n",
    "query = '''\n",
    "SELECT count(distinct ui_acct)\n",
    "FROM kcmo_lehd.mo_qcew_employers\n",
    "WHERE legal_name is NULL\n",
    "'''\n",
    "# read it\n",
    "missing_names = pd.read_sql(query, conn)\n",
    "missing_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Discuss with your team:** what we should do about these missing values?\n",
    ">\n",
    "> If you feel up to the challenge, try coding one of your team's ideas here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### your code...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics on Different Datasets\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In this section, let's start looking at aggregate statistics on the data. We are interested in the distribution of jobs by industrial classification, so let's take a look at the overall distribution in 2015.\n",
    "\n",
    "How many jobs are there in the state? Look at Wages records by year/quarter, empr data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ LODES Data: Workplace Area Characteristics File__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT *\n",
    "FROM public.lodes_workplace_area_characteristics\n",
    "WHERE segment = 'S000' AND jobtype = 'JT01' AND state = 'mo'\n",
    "LIMIT 20;\n",
    "'''\n",
    "\n",
    "wac = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wac.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wac.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take some time to look at the documentation and understand what the different column names refer to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run summary statistics on number of jobs per industry (NAICS code), let's begin by creating a list of the variables that refer to Industry counts. Referring to the documentation, these columns are the ones beginning with \"CN\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_col = [col for col in wac if col.startswith('cn')]\n",
    "print (filter_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This line of code may look complicated, so let's break it down step by step:\n",
    ">\n",
    "> 1. __`... for col in wac ...`__ - Loop through every element `col` (columns) in the object `wac`\n",
    "> 2. __`... if col.startswith('cn')`__ - Restrict to columns that begin with 'cn'\n",
    "> 3. __`col ...`__ - Return column names\n",
    ">\n",
    "> _Additional Note: This formulation is known as \"list comprehension\"._ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a list of all the industry variables, let's create the SQL query. For each one of these variables, we want the sum of industry workers across by year. We therefore want to group the dataset by year. The SQL query can be formulated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "    year'''\n",
    "\n",
    "for col in filter_col:\n",
    "    query += '''\n",
    "    , sum({0:}) as {0:}'''.format(col)\n",
    "\n",
    "query += '''\n",
    "FROM public.lodes_workplace_area_characteristics\n",
    "WHERE segment = 'S000' AND jobtype = 'JT01' AND state = 'mo'\n",
    "GROUP BY year\n",
    "ORDER BY year\n",
    "'''\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wac_year_stats = pd.read_sql(query, conn, index_col='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's view the transposed data (in order to have the years as columns)\n",
    "wac_year_stats.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the values into the percentage of all jobs that year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wac_year_stats['total_jobs'] = wac_year_stats.sum(axis=1)\n",
    "for var in filter_col:\n",
    "    wac_year_stats[var] = (wac_year_stats[var]/wac_year_stats['total_jobs'])*100\n",
    "del wac_year_stats['total_jobs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}%'.format\n",
    "wac_year_stats.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Combining Datasets\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "While the LODES data gives interesting information about the distribution of jobs by industry at block level over the entire Missouri state, we would like to restrict our analysis to the city of Kansas City. Unfortunately there is no metropolitan area information on the LODES dataset. The only way of restricting to Kansas City is to first merge on the geographic information from the crosswalk file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ LODES Data: Crosswalk File __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT *\n",
    "FROM lodes_census_geography_crosswalk_mo\n",
    "'''\n",
    "\n",
    "xwalk = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, take some time to look at the documentation and understand all the levels of geography in the crosswalk file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xwalk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(xwalk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which variable best characterizes the geographic area of interest for our analysis?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A closer look at the data and documentation leads us to use `stplcname == Kansas City city, MO` to refer to the metropolitan area of Kansas City, MO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xwalk_kcmo = xwalk[xwalk['stplcname']==\"Kansas City city, MO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xwalk_kcmo.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT a.*\n",
    "    , b.tabblk2010\n",
    "    , b.cty\n",
    "    , b.ctyname\n",
    "    , b.stplc\n",
    "    , b.stplcname\n",
    "FROM (\n",
    "    SELECT *\n",
    "    FROM lodes_workplace_area_characteristics\n",
    "    WHERE segment = 'S000' AND jobtype = 'JT01' AND state = 'mo'\n",
    ") AS a\n",
    "LEFT JOIN lodes_census_geography_crosswalk_mo AS b\n",
    "ON a.w_geocode = b.tabblk2010\n",
    "WHERE b.stplcname = 'Kansas City city, MO'\n",
    "LIMIT 20;\n",
    "'''  \n",
    "kcmo_wac = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can conduct the same analysis as before on the the area of Kansas City, MO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following SQL query will directly merge on the relevant geographic information, \n",
    "# and restrict to the value of interest (where `stplcname` is \"Kansas City city, MO\").\n",
    "filter_col = [col for col in kcmo_wac if col.startswith('cn')]\n",
    "\n",
    "query = '''\n",
    "SELECT\n",
    "    year'''\n",
    "\n",
    "for col in filter_col:\n",
    "    query += '''\n",
    "    , sum({0:}) as {0:}'''.format(col)\n",
    "\n",
    "query += '''\n",
    "FROM (\n",
    "    SELECT a.*\n",
    "        , b.tabblk2010\n",
    "        , b.cty\n",
    "        , b.ctyname\n",
    "        , b.stplc\n",
    "        , b.stplcname\n",
    "    FROM (\n",
    "        SELECT *\n",
    "        FROM lodes_workplace_area_characteristics\n",
    "        WHERE segment = 'S000' AND jobtype = 'JT01' AND state = 'mo'\n",
    "    ) AS a\n",
    "    LEFT JOIN lodes_census_geography_crosswalk_mo AS b\n",
    "    ON a.w_geocode = b.tabblk2010\n",
    "    WHERE b.stplcname = 'Kansas City city, MO'\n",
    ") AS c\n",
    "GROUP BY year\n",
    "ORDER BY year\n",
    "'''\n",
    "\n",
    "wac_kcmo_year_stats = pd.read_sql(query, conn, index_col='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wac_kcmo_year_stats.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating New Measures\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "One important aspect of data analysis is creating additional features from the ones originally present in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preliminary Example**\n",
    "\n",
    "For example, the Missouri QCEW Employers Data has information on the number of employees in a quarter and the total wages paid by the Employer over the same time period. We can easily create a new feature of Average Wage paid by the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT year\n",
    "        , qtr\n",
    "        , legal_name\n",
    "        , total_wage\n",
    "        , mon1_empl\n",
    "        , mon2_empl\n",
    "        , mon3_empl\n",
    "FROM kcmo_lehd.mo_qcew_employers\n",
    "LIMIT 20\n",
    "'''\n",
    "employers_wages = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employers_wages['avg_wage'] = employers_wages['total_wage']/(employers_wages['mon1_empl']\n",
    "                                                             +employers_wages['mon2_empl']\n",
    "                                                             +employers_wages['mon3_empl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employers_wages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We notice data inconsistencies that result in infinite wages. These are things we will have to keep in mind when we run analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Replicating the QWI Statistics__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For another example of feature creation, please turn to the \"QWI Statistics\" notebook. In this notebook, we replicate the QWI Census framework using MO wage records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Thinking back of the theme of Economic Development, what would be an interesting metric to track? How would you calculate it? How has it evolved in the last few years? Some ideas are given below.\n",
    "\n",
    "> How many new businesses were created by industry in a given year? How does this compare to the previous, next years?\n",
    "\n",
    "> How many individuals were working in Missouri during a given year? Do they work in all 4 quarter? How does this compare to the other years of data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metric\n",
    "# Do frequency table by year\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Results\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "We ask that you submit the your results for this exercice by saving a CSV file in a shared folder. Please run the cells below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_file = df.copy()\n",
    "# Replace df with the name of your export table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myname = !whoami\n",
    "export_file.to_csv(\n",
    "    '/nfshome/{0}/Projects/ada_kcmo/shared/Class_Submits/Variables/{0}.csv'.format(myname[0])\n",
    "    , index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "1072px",
    "left": "324px",
    "top": "193.958px",
    "width": "338px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
