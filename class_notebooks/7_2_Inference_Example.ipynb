{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Example\n",
    "\n",
    "#### Table of Contents\n",
    "<a id='toc'></a>\n",
    "- [Setup](#setup)\n",
    "- [Imputation](#imputation)\n",
    "- [Create Features/Labels](#createfeatures)\n",
    "- [Logistic Regression](#logreg)\n",
    "- [Machine Learning](#machinelearning)\n",
    "- [Adding Group Membership](#groupmember)\n",
    "    - [Logistic with Group Feature](#grouplog)\n",
    "    - [ML with Group Features](#groupml)\n",
    "\n",
    "\n",
    "During the lecture today we discussed different factors that can affect inference.  As a result of this notebook you will learn how a \"grouping\" variable can impact the fit of a model.  We'll also be reviewing some of the ML code you saw during the last session.\n",
    "\n",
    "The dataset used in this notebook is ada_class3.for_inference_example and was developed for this purpose.  It is a subset of household benefit spells reported as ending within 2013.  There are over 200k rows in the dataset.\n",
    "\n",
    "Our goal with this analysis is to predict individuals returning to benefits within 1 year after the end of a benefit spell.  Variables that will be used in this analysis are listed below.  The majority of the features will be what we will consider \"individual variables,\" and we'll consider the *district* variable a group variable.  We will first run models with the individual features, and then see if the inclusion of the group variable changes our model output/prediction.\n",
    "\n",
    "We will first look at the more familiar Logistic Regression, then at ML models we learned in the last class session.\n",
    "\n",
    "## Important Variables\n",
    "---\n",
    "### Identification Variables\n",
    "* receptno = IDHS provided receipt number\n",
    "* ch_dpa_caseid = Chapin Hall Case ID number\n",
    "* new_id = unique row id number created for this dataset\n",
    "* start_date\n",
    "* end_date\n",
    "\n",
    "### Features/Grouping Variables\n",
    "*note that variables from the case records may have missingness*\n",
    "\n",
    "* benefit_type \n",
    "* sex\n",
    "* rac\n",
    "* rootrace\n",
    "* foreignbrn\n",
    "* edlevel\n",
    "* health\n",
    "* martlst\n",
    "* workexp\n",
    "* district\n",
    "* homeless\n",
    "\n",
    "#### Features Developed From Wage Table\n",
    "* has_job_win1yr = 0/1 indicating any wage table employment within one year\n",
    "* lose_job_win1yr = 0/1 indicating that had wage table employment and then did not within one year\n",
    "* has_job_q(1-4) = 0/1 variable for each of the 4 quarters in the year after end_date indicating employment\n",
    "* wage_q(1-4) = wage total for each quarter (could be from multiple jobs)\n",
    "* total_wage_1yr = sum of all the wages within the year following end_date\n",
    "\n",
    "### Labels/Outcome Variables\n",
    "* new_spell_win1yr = 0/1 variable indicating a new spell within one year of end date of spell\n",
    "* new_spell_win1yr_benefit = same as above, but has to be same benefit_type (tanf, foodstamps, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "<a id='setup'></a>\n",
    "- Return to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier,\n",
    "                              GradientBoostingClassifier,\n",
    "                              AdaBoostClassifier)\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sqlalchemy\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_name = \"appliedda\"\n",
    "hostname = \"10.10.2.10\"\n",
    "conn = psycopg2.connect(database=db_name, host = hostname) #database connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load some of Avishek's function defintions to help with model comparison\n",
    "def plot_precision_recall_n(y_true, y_prob, model_name):\n",
    "    \"\"\"\n",
    "    y_true: ls \n",
    "        ls of ground truth labels\n",
    "    y_prob: ls\n",
    "        ls of predic proba from model\n",
    "    model_name: str\n",
    "        str of model name (e.g, LR_123)\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    y_score = y_prob\n",
    "    precision_curve, recall_curve, pr_thresholds = precision_recall_curve(y_true, y_score)\n",
    "    precision_curve = precision_curve[:-1]\n",
    "    recall_curve = recall_curve[:-1]\n",
    "    pct_above_per_thresh = []\n",
    "    number_scored = len(y_score)\n",
    "    for value in pr_thresholds:\n",
    "        num_above_thresh = len(y_score[y_score>=value])\n",
    "        pct_above_thresh = num_above_thresh / float(number_scored)\n",
    "        pct_above_per_thresh.append(pct_above_thresh)\n",
    "    pct_above_per_thresh = np.array(pct_above_per_thresh)\n",
    "    plt.clf()\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(pct_above_per_thresh, precision_curve, 'b')\n",
    "    ax1.set_xlabel('percent of population')\n",
    "    ax1.set_ylabel('precision', color='b')\n",
    "    ax1.set_ylim(0,1.05)\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(pct_above_per_thresh, recall_curve, 'r')\n",
    "    ax2.set_ylabel('recall', color='r')\n",
    "    ax2.set_ylim(0,1.05)\n",
    "    \n",
    "    name = model_name\n",
    "    plt.title(name)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "def precision_at_k(y_true, y_scores,k):\n",
    "    \n",
    "    threshold = np.sort(y_scores)[::-1][int(k*len(y_scores))]\n",
    "    y_pred = np.asarray([1 if i >= threshold else 0 for i in y_scores ])\n",
    "    return precision_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select_statement = \"\"\"SELECT new_id, sex, rootrace, edlevel, workexp, martlst, homeless, benefit_type,\n",
    "                    has_job_q1, has_job_q2, has_job_q3, has_job_q4, wage_q1, wage_q2, wage_q3, wage_q4,\n",
    "                    has_job_win1yr, lose_job_win1yr, total_wage_1yr, new_spell_win1yr, new_spell_win1yr_benefit,\n",
    "                    district FROM ada_class3.for_inference_example WHERE total_wage_1yr IS NOT NULL;\"\"\"\n",
    "df = pd.read_sql( select_statement, conn )\n",
    "print df.shape\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation\n",
    "<a id='imputation'></a>\n",
    "- Return to [Table of Contents](#toc)\n",
    "\n",
    "We can see from just the few rows above that there is clearly missing data.  Because our variables are categorical, we cannot simply impute the mean for the missing values.  Instead, we will add a 0/1 variable for missing in each variable that will be another feature/predictor used in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['sex_miss'] = (df['sex'] == 0)\n",
    "df['race_miss'] = (df['rootrace'] == 0)\n",
    "df['ed_miss'] = (df['edlevel'] == None)\n",
    "df['mar_miss'] = (df['martlst'] == 0)\n",
    "df['home_miss'] = (df['homeless'] == None)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create Features\n",
    "<a id='createfeatures'></a>\n",
    "- Return to [Table of Contents](#toc)\n",
    "\n",
    "We need to create 0/1 \"dummy\" variables/features for the rest of the different levels of the predictors we want to include in our model. At the end of this code block we set up two different feature tables - one with the yearly employment features and the other with the quarterly employment features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sex\n",
    "df['male'] = (df['sex'] == 1)\n",
    "df['female'] = (df['sex'] == 2)\n",
    "#rootrace\n",
    "df['nhwhite'] = (df['rootrace'] == 1)\n",
    "df['nhblack'] = (df['rootrace'] == 2)\n",
    "df['native'] = (df['rootrace'] == 3)\n",
    "df['hispanic'] = (df['rootrace'] == 6)\n",
    "df['asian'] = (df['rootrace'] == 7)\n",
    "#edlevel\n",
    "less_list = ['A', 'B', 'C', 'D', 1, 2, 3]\n",
    "somehs_list = ['E', 'F', 4]\n",
    "hsgrad_list = ['G', 'H', 'V', 5]\n",
    "somecoll_list = ['W', 'X', 'Y', 6]\n",
    "collgrad_list = ['Z', 'P', 7]\n",
    "df['lessthanhs'] = (df['edlevel'].isin(less_list))\n",
    "df['somehs'] = (df['edlevel'].isin(somehs_list))\n",
    "df['hsgrad'] = (df['edlevel'].isin(hsgrad_list))\n",
    "df['somecoll'] = (df['edlevel'].isin(somecoll_list))\n",
    "df['collgrad'] = (df['edlevel'].isin(collgrad_list))\n",
    "#workexp\n",
    "df['noattach'] = (df['workexp'] == 0)\n",
    "df['nowkexp'] = (df['workexp'] == 1)\n",
    "df['prof'] = (df['workexp'] == 2)\n",
    "df['othermgr'] = (df['workexp'] == 3)\n",
    "df['clerical'] = (df['workexp'] == 4)\n",
    "df['sales'] = (df['workexp'] == 5)\n",
    "df['crafts'] = (df['workexp'] == 6)\n",
    "df['oper'] = (df['workexp'] == 7)\n",
    "df['service'] = (df['workexp'] == 8)\n",
    "df['labor'] = (df['workexp'] == 9)\n",
    "#martlst\n",
    "df['nvrmar'] = (df['martlst'] == 1)\n",
    "df['marwspouse'] = (df['martlst'] == 2)\n",
    "df['marwospouse'] = (df['martlst'].isin([3,4,6]))\n",
    "df['sepordiv'] = (df['martlst'].isin([5,7]))\n",
    "df['widow'] = (df['martlst'] == 8)\n",
    "#homeless\n",
    "df['nothomeless'] = (df['homeless'] == 'N')\n",
    "df['ishomeless'] = (df['homeless'].isin(['1','2','3','4','Y']))\n",
    "#benefit_type\n",
    "df['foodstamp'] = (df['benefit_type'] == 'foodstamp')\n",
    "df['tanf'] = (df['benefit_type'] == 'tanf46')\n",
    "df['grant'] = (df['benefit_type'] == 'grant')\n",
    "#create features df\n",
    "\n",
    "df_features = df[['male', 'female', 'nhwhite', 'nhblack', 'native', 'hispanic', 'asian', 'lessthanhs', \n",
    "                  'somehs', 'hsgrad', 'somecoll', 'collgrad', 'noattach', 'nowkexp', 'prof', 'othermgr',\n",
    "                  'clerical', 'sales', 'crafts', 'oper', 'service', 'labor', 'nvrmar', 'marwspouse', \n",
    "                  'sepordiv', 'widow', 'nothomeless', 'ishomeless', 'foodstamp', 'tanf', 'grant']].copy()\n",
    "# features df with qtr based job variables\n",
    "df_features_wjobqtr = df[['has_job_q1', 'has_job_q2', 'has_job_q3', 'has_job_q4',\n",
    "                'wage_q1', 'wage_q2', 'wage_q3', 'wage_q4']].copy()\n",
    "df_features_wjobqtr.join(df_features) \n",
    "# features df with year based job variables\n",
    "df_features_wjobyr = df[['has_job_win1yr', 'lose_job_win1yr', 'total_wage_1yr']].copy()\n",
    "df_features_wjobyr = df_features_wjobyr.join(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print frequencies of dummy variables - for disclosure review.\n",
    "feat_list = list(df_features)\n",
    "for item in feat_list:\n",
    "    print pd.crosstab(index=df_features[item], columns = \"count\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Labels\n",
    "The labels dataframes each have just one column, the outcome variable for your model.  Below we've created two, one for returns to any benefit within the year after a spell, the other is an indicator for return to the same benefit within the year.  We'll be using the first in the examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_label_returnany = df[['new_spell_win1yr']].copy()\n",
    "df_label_returnsame = df[['new_spell_win1yr_benefit']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with a more familiar model - Logistic Regression\n",
    "<a id='logreg'></a>\n",
    "- Return to [Table of Contents](#toc)\n",
    "\n",
    "We'll first fit a logistic regression model to predict return to benefits based on the individual predictors we have selected.  Typically when a social scientist uses this type of model it is to describe the individual predictors' effects on some outcome, therefore the entire dataset is used to fit the model.\n",
    "\n",
    "Unlike in the ML class, we will be using the package *statsmodels* to run our Logistic Regression models, since it provides many more output options/functions vs. sci-kit learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create one df and set up listings of variables for below\n",
    "#drop reference categories (missing, male)\n",
    "df_features_forlr = df_features_wjobyr[['female', 'nhwhite', 'nhblack', 'native', 'hispanic', 'asian', 'lessthanhs',\n",
    "                                        'somehs', 'hsgrad', 'somecoll', 'collgrad', 'noattach', 'nowkexp', 'prof', 'othermgr', \n",
    "                                        'clerical', 'sales', 'crafts', 'oper', 'service', 'labor', 'nvrmar', 'marwspouse', \n",
    "                                        'sepordiv', 'widow', 'nothomeless', 'ishomeless', 'foodstamp', 'tanf', 'grant', \n",
    "                                        'has_job_win1yr', 'lose_job_win1yr', 'total_wage_1yr']].copy()\n",
    "df_lrmodel = df_features_forlr.join(df_label_returnany)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*statsmodels* takes as an argument a string with your model specification, in a format you may be familiar with if you have used R in the past.  In order to build that list I'll employ some code to avoid typing all the variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get list of features to build model statement\n",
    "feat_list = list(df_features_forlr)\n",
    "print feat_list\n",
    "print len(feat_list)\n",
    "length = len(feat_list)\n",
    "\n",
    "#create string of features with plus signs\n",
    "count = 0\n",
    "feat_string = ''\n",
    "for feature in feat_list:\n",
    "    count += 1\n",
    "    if count < (length):\n",
    "        feat_string += feature \n",
    "        feat_string += ' + '\n",
    "    else:\n",
    "        feat_string += feature\n",
    "## END FOR BLOCK\n",
    "\n",
    "print feat_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "formula = \"new_spell_win1yr ~ \" + feat_string\n",
    "print (formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fit model - note the procedure is glm so you have to specify binomial in the family argument to get LR\n",
    "model =smf.glm(formula=formula, data=df_lrmodel, family=sm.families.Binomial())\n",
    "result = model.fit()\n",
    "print (result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's no surprise that the majority of the coefficients are significant - with Ns this large significance becomes pretty meaningless.  Looking at the direction of the coefficients, we start to see which variables impact the probability of going back on benefits either positive or negatively.  For female and nhblack (Non-Hispanic Blacks) we see they are more likely to return to benefits (reference values are male and missing-race).  On the other hand nhwhite (Non-Hispanic Whites) are less likely to return.\n",
    "\n",
    "This package also has the benefit of returning a model output summary familiar to any SAS or stata user.  We can also get just the values using .params or .pvalues (for example result.params contains just the coefficients for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (result.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we have run this model how a statistician would typically - using all of the data to fit the model.  In our ML notebook we learned about using training and test sets of data to show the strength of the model in predicting a subsequent outcome.  This can also be done with the logistic regression as we saw in the ML notebook.  Below we'll work through it in *statsmodels* with our same data from above.  So we can cut our dataframe into train and test sets.  Here I'll use the index (row numbers) to cut the dataframe into roughly 80/20 train/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_lrtrain = df_lrmodel[:201540]\n",
    "df_lrtest = df_lrmodel[201540:]\n",
    "print df_lrtrain.shape\n",
    "print df_lrtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fit model - this time we're only fitting the model to the training set.\n",
    "model =smf.glm(formula=formula, data=df_lrtrain, family=sm.families.Binomial())\n",
    "result = model.fit()\n",
    "print (result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is fitting the model to just 80% of the data that we used above, however, as to be expected, the resulting coefficients are largely similar.  \n",
    "\n",
    "Compared to the first model, we get:\n",
    "\n",
    "XXX\n",
    "\n",
    "Any coefficients with larger changes between this model (like native which went from XXX) is because we cut data out of our dataset in a not exactly random way and those are rarer instances.\n",
    "\n",
    "Now we can use these coefficients to make predictions on the test set and see how well our model works for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "predictions = result.predict(df_lrtest)\n",
    "\n",
    "pred_binary = (predictions > 0.5)\n",
    "\n",
    "print (\"confusion matrix\")\n",
    "print confusion_matrix(df_lrtest['new_spell_win1yr'], pred_binary )\n",
    "print classification_report(df_lrtest['new_spell_win1yr'], pred_binary, digits=3 )\n",
    "\n",
    "plot_precision_recall_n(df_lrtest['new_spell_win1yr'], predictions, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Moving to Machine Learning\n",
    "<a id='machinelearning'></a>\n",
    "- Return to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create Testing/Training sets of both Features and Labels sets\n",
    "We're going to start with using the features table with the yearly job variables and the label that indicates a return to any form of benefits.\n",
    "\n",
    "This is the same code as we used in the ML notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features_wjobyr, df_label_returnany, test_size = 0.2)\n",
    "print X_train.shape, y_train.shape\n",
    "print X_test.shape, y_test.shape\n",
    "sel_features = list(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running through the ML models\n",
    "Below is again code familiar from the ML notebook.  We set up our arguments in a dictionary so that we can loop through the models and print the results using the same code.\n",
    "\n",
    "Again we're using the full set of features to predict returning to benefits within 1 year of the end of a spell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs = {'RF': RandomForestClassifier(n_estimators=50, n_jobs=-1),\n",
    "       'ET': ExtraTreesClassifier(n_estimators=10, n_jobs=-1, criterion='entropy'),\n",
    "        'LR': LogisticRegression(penalty='l1', C=1e5),\n",
    "        'SGD':SGDClassifier(loss='log'),\n",
    "        'GB': GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, random_state=17, n_estimators=10),\n",
    "        'NB': GaussianNB()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sel_clfs = ['RF', 'ET', 'LR', 'SGD', 'GB', 'NB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_p_at_k = 0\n",
    "for clfNM in sel_clfs:\n",
    "    clf = clfs[clfNM]\n",
    "    clf.fit( X_train, y_train.values.ravel() )\n",
    "    print clf\n",
    "    y_score = clf.predict_proba(X_test)[:,1]\n",
    "    predicted = np.array(y_score)\n",
    "    expected = np.array(y_test)\n",
    "    plot_precision_recall_n(expected,predicted, clfNM)\n",
    "    p_at_1 = precision_at_k(expected,y_score, 0.05)  ## note that i changed the k value here from 0.01 to 0.05\n",
    "    print('Precision at 5%: {:.2f}'.format(p_at_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, the Precision at %5 values for the 6 models are:\n",
    "\n",
    "* XXXX\n",
    "\n",
    "To get the best prediction for our money, we'll probably want to choose a model with high precision at 5% (the level of funding we can afford). \n",
    "\n",
    "Focusing on the ML models with highest precision at %5, we'll look at the feature importances for these two ML models (Random Forest and Gradient Boosting).\n",
    "\n",
    "Feature importances indicate which variables are most important to the prediction/classification of cases as the trees split.  Features at earlier/higher splits are more important than those at lower levels in the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select only the two ML models\n",
    "sel_clfs = ['RF', 'GB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#here I've adapted the model loop from above to print feature importances instead of the precision/recall graph\n",
    "\n",
    "for clfNM in sel_clfs:\n",
    "    clf = clfs[clfNM]\n",
    "    clf.fit( X_train, y_train.values.ravel() )\n",
    "    print clf\n",
    "    y_score = clf.predict_proba(X_test)[:,1]\n",
    "    predicted = np.array(y_score)\n",
    "    expected = np.array(y_test)\n",
    "    \n",
    "    var_names = list(X_train) # get a list of variable names\n",
    "        \n",
    "    importances = clf.feature_importances_ # get the feature importances\n",
    "    indices = np.argsort(importances)[::-1] # sort the list to get the highest importance first\n",
    "    \n",
    "    for f in range(X_train.shape[1]):\n",
    "        print (\"%d. feature (%s) importance = %f\" % (f + 1, var_names[indices[f]], importances[indices[f]]))    \n",
    "    \n",
    "\n",
    "    p_at_1 = precision_at_k(expected,y_score, 0.05)\n",
    "    print('Precision at 5%: {:.2f}'.format(p_at_1))\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important features in the Random Forest Model are:\n",
    "1. total_wage_1yr \n",
    "2. nothomeless \n",
    "3. nvrmar\n",
    "4. hsgrad\n",
    "5. noattach\n",
    "\n",
    "This makes sense - wages and homelessness status likely have a huge impact on whether a person returns to benefits within the year or not.\n",
    "\n",
    "The most important features in the Gradient Boosting Model are:\n",
    "1. nothomeless\n",
    "2. nvrmar\n",
    "3. total_wage_1yr\n",
    "4. foodstamp\n",
    "5. hsgrad\n",
    "\n",
    "Again we see most of the same variables.  The slight differences are due to the different ways in which these models are processing the same data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Will Adding a Group Membership Variable make a difference?\n",
    "<a id='groupmember'></a>\n",
    "- Return to [Table of Contents](#toc)\n",
    "\n",
    "We'll add in the district variable and see if it makes a difference in either our prediction or our coefficients/feature importances.  Adding this variable could improve prediction to the extent that it is new information not already contained within the other features.  It can also change the coefficients in a logistic model or the feature importances in a ML model if there are clusters of individuals in the groups who are alike on that particular feature.  For example, if there are more individuals of a particular race collected in one of the groups, not including the group variable meant that the race variable was partially serving as \"proxy\" for the group membership.  Adding the group membership to the model lets you see the effect of race above and beyond the clustering.\n",
    "\n",
    "We will use the *district* variable and split it into two groupings - downstate (codes 10-115) and Cook County (codes 200-294). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['cookcty'] = ((df['district'] >= 200) & (df['district'] <= 294))\n",
    "df['downstate'] = ((df['district'] >= 10) & (df['district'] <= 115))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return to Logistic Regression\n",
    "<a id='grouplog'></a>\n",
    "- Return to [Table of Contents](#toc)\n",
    "\n",
    "Adding in our new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add new cookcty to df for logistic regression\n",
    "df_lrmodel['cookcty'] = df['cookcty']\n",
    "df_lrtrain = df_lrmodel[:201540]\n",
    "df_lrtest = df_lrmodel[201540:]\n",
    "print df_lrtrain.shape\n",
    "print df_lrtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "formula += \" + cookcty\" \n",
    "model =smf.glm(formula=formula, data=df_lrtrain, family=sm.families.Binomial())\n",
    "result = model.fit()\n",
    "print (result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to our previous LR model, we get:\n",
    "\n",
    "XXX\n",
    "\n",
    "So adding the group variable did account for some of the race effects we were seeing in the previous model.\n",
    "\n",
    "We also see cookcty has a coefficient of XXX, reflecting the power that group membership has on the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "predictions = result.predict(df_lrtest)\n",
    "\n",
    "pred_binary = (predictions > 0.5)\n",
    "\n",
    "\n",
    "print confusion_matrix(df_lrtest['new_spell_win1yr'], pred_binary )\n",
    "print classification_report(df_lrtest['new_spell_win1yr'], pred_binary, digits=3 )\n",
    "\n",
    "plot_precision_recall_n(df_lrtest['new_spell_win1yr'], predictions, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slight improvement to the precision is reflected in the graph above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Will ML Models be changed?\n",
    "<a id='groupml'></a>\n",
    "- Return to [Table of Contents](#toc)\n",
    "\n",
    "We saw an impact of adding this grouping variable in the Logistic Regression.  Will it improve the predictive power of our ML models?  Will it be an important feature?\n",
    "\n",
    "None of our model fitting code is changed below - we're just adding two new features and rerunning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_features_wjobyr['cookcty'] = df['cookcty']\n",
    "df_features_wjobyr['downstate'] =df['downstate']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features_wjobyr, df_label_returnany, test_size = 0.2)\n",
    "print X_train.shape, y_train.shape\n",
    "print X_test.shape, y_test.shape\n",
    "sel_features = list(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sel_clfs = ['RF', 'ET', 'LR', 'SGD', 'GB', 'NB']\n",
    "max_p_at_k = 0\n",
    "for clfNM in sel_clfs:\n",
    "    clf = clfs[clfNM]\n",
    "    clf.fit( X_train, y_train.values.ravel() )\n",
    "    print clf\n",
    "    y_score = clf.predict_proba(X_test)[:,1]\n",
    "    predicted = np.array(y_score)\n",
    "    expected = np.array(y_test)\n",
    "    plot_precision_recall_n(expected,predicted, clfNM)\n",
    "    p_at_1 = precision_at_k(expected,y_score, 0.05)\n",
    "    print('Precision at 5%: {:.2f}'.format(p_at_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Precision at %5 did not substantially improve with any of the models.  And the prediction power of the SGD model was decreased.\n",
    "\n",
    "* XXX\n",
    "\n",
    "We'll again look at the feature importances to see if there are any substantial changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sel_clfs = ['RF', 'GB']\n",
    "for clfNM in sel_clfs:\n",
    "    clf = clfs[clfNM]\n",
    "    clf.fit( X_train, y_train.values.ravel() )\n",
    "    print clf\n",
    "    y_score = clf.predict_proba(X_test)[:,1]\n",
    "    predicted = np.array(y_score)\n",
    "    expected = np.array(y_test)\n",
    "    \n",
    "    var_names = list(X_train)\n",
    "        \n",
    "    importances = clf.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    for f in range(X_train.shape[1]):\n",
    "        print (\"%d. feature (%s) importance = %f\" % (f + 1, var_names[indices[f]], importances[indices[f]]))    \n",
    "    \n",
    "\n",
    "    p_at_1 = precision_at_k(expected,y_score, 0.05)\n",
    "    print('Precision at 5%: {:.2f}'.format(p_at_1))\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our most important features in each model are largely unchanged.  *cookcty* and *downstate* show up as 16th and 21st most important features in the Random Forest model, respectively.  In the Gradient Boosing model, though, *cookcty* shows up 5th, indicating it was an important classifier, however the resulting output slightly lowered our precision at 5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
